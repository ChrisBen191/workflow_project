{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this allows the 'data_prep' file to be ran before this file tries to bring in those datasets\n",
    "# os.system(\"python data_prep.py\")\n",
    "\n",
    "# this is from the datasets with non-corrected 'gm r4f' dates\n",
    "# os.system(\"python data_prep_without_corrections.py\")\n",
    "\n",
    "# imports the 'project table' data\n",
    "project_table_data = \"./data/cleaned_data/project_table.csv\"\n",
    "project_table_df = pd.read_csv(\n",
    "    project_table_data, dtype={\n",
    "        'Claim #': str,\n",
    "        'Job #': str,\n",
    "        'Branch':str,\n",
    "        'Claim Status':str},\n",
    "    parse_dates=[\n",
    "        'Rep Agreement Signed', 'Rep Claim Collected','FTA Scope Completed',\n",
    "        'FTA Scope Rejected', 'BC Estimate Completed','OB Scope Completed',\n",
    "        'Sup Job Submitted', 'BC Approved for Production', 'OB Order Built',\n",
    "        'GM Order Processed', 'PA Permit Applied', 'PA Permit Processed',\n",
    "        'PA OA Processed', 'PA OA Invoiced', 'PA Notify of Delivery',\n",
    "        'PA Notify of Start', 'Delivery Date', 'Roof Start',\n",
    "        'Roof End', 'GM Approved for Inspection', 'GM Change Order Date',\n",
    "        'GM Labor Adjustment Date', 'RA Inspection Requested', 'RA Inspection Processed', \n",
    "        'Rep COC Collected', 'SA Job Docs Uploaded', 'BC Project Invoiced','BC Project Closed'])\n",
    "\n",
    "# imports the 'project information' data\n",
    "project_info_data = \"./data/cleaned_data/project_info_table.csv\"\n",
    "project_info_df = pd.read_csv(project_info_data, dtype=str)\n",
    "\n",
    "# imports 'workflow table' data\n",
    "workflow_table_data = \"./data/cleaned_data/workflow_table.csv\"\n",
    "workflow_table_df = pd.read_csv(workflow_table_data)\n",
    "\n",
    "# imports the 'eagleview table' data\n",
    "eagleview_table_data = \"./data/eagleview_analysis.csv\"\n",
    "eagleview_table_df = pd.read_csv(eagleview_table_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project_table_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Claim #', 'Job #', 'Branch', 'City', 'Building Department',\n",
       "       'Permit Req?', 'Supplier Name', 'Crew', 'Insurance Company',\n",
       "       'Multi-rejected', 'Scope Rejections', 'Change Orders',\n",
       "       'Labor Adjustments', 'Sup', 'Rep', 'FTA', 'BC', 'OB', 'GM'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_info_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim #                object\n",
       "Job #                  object\n",
       "Branch                 object\n",
       "City                   object\n",
       "Building Department    object\n",
       "Permit Req?            object\n",
       "Supplier Name          object\n",
       "Crew                   object\n",
       "Insurance Company      object\n",
       "Multi-rejected         object\n",
       "Scope Rejections       object\n",
       "Change Orders          object\n",
       "Labor Adjustments      object\n",
       "Sup                    object\n",
       "Rep                    object\n",
       "FTA                    object\n",
       "BC                     object\n",
       "OB                     object\n",
       "GM                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_info_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow_table_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Claim #', 'Job #', 'Square Feet', 'Ridges', 'Hips', 'Valleys', 'Rakes',\n",
       "       'Eaves'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eagleview_table_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fort Collins         629\n",
       "Colorado Springs     184\n",
       "Denver               157\n",
       "Kansas City          151\n",
       "Omaha                145\n",
       "Clinton               87\n",
       "Longmont              79\n",
       "Castle Rock           74\n",
       "Saint Joseph          73\n",
       "Westminster           62\n",
       "Loveland              52\n",
       "Windsor               48\n",
       "fort collins          46\n",
       "Littleton             43\n",
       "Johnstown             43\n",
       "Pueblo                38\n",
       "Savannah              34\n",
       "Lincoln               32\n",
       "Liberty               30\n",
       "Erie                  24\n",
       "Merriam               23\n",
       "Clinton               22\n",
       "Prairie Village       19\n",
       "Saint Joseph          18\n",
       "Pueblo West           18\n",
       "Overland Park         15\n",
       "Fort Collins          14\n",
       "Blue Springs          14\n",
       "Firestone             13\n",
       "Broomfield            12\n",
       "                    ... \n",
       "St. Joseph             1\n",
       "Dever                  1\n",
       "Englewood              1\n",
       "Denver,                1\n",
       "Dearborn               1\n",
       "Fortr Collins          1\n",
       "Fort Lupton            1\n",
       "Lawson                 1\n",
       "Cleveland              1\n",
       "Layfayette             1\n",
       "Roeland Park           1\n",
       "Berthod                1\n",
       "Olathe                 1\n",
       "Longmont               1\n",
       "Elkorn                 1\n",
       "Westwood Hills         1\n",
       "Northglen              1\n",
       "Ferderick              1\n",
       "Keenesburg             1\n",
       "Claycomo               1\n",
       "Stapleton              1\n",
       "Cameron                1\n",
       "Greenwood Village      1\n",
       "Fort Collons           1\n",
       "Linwood                1\n",
       "Basehor                1\n",
       "liberty                1\n",
       "denver                 1\n",
       "Red Feather Lakes      1\n",
       "Berthoud               1\n",
       "Name: City, Length: 162, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_info_df.head(25)\n",
    "project_info_df['City'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FORT COLLINS         685\n",
       "COLORADO SPRINGS     191\n",
       "DENVER               158\n",
       "KANSAS CITY          151\n",
       "OMAHA                149\n",
       "LONGMONT              88\n",
       "CLINTON               87\n",
       "CASTLE ROCK           74\n",
       "SAINT JOSEPH          73\n",
       "WESTMINSTER           64\n",
       "LOVELAND              52\n",
       "WINDSOR               48\n",
       "LITTLETON             43\n",
       "JOHNSTOWN             43\n",
       "PUEBLO                39\n",
       "SAVANNAH              34\n",
       "LINCOLN               32\n",
       "LIBERTY               31\n",
       "MERRIAM               27\n",
       "ERIE                  24\n",
       "CLINTON               22\n",
       "PRAIRIE VILLAGE       19\n",
       "SAINT JOSEPH          18\n",
       "PUEBLO WEST           18\n",
       "OVERLAND PARK         15\n",
       "BLUE SPRINGS          14\n",
       "FORT COLLINS          14\n",
       "FIRESTONE             13\n",
       "BROOMFIELD            13\n",
       "CHEYENNE              12\n",
       "                    ... \n",
       "NORTHGLEN              1\n",
       "BASEHOR                1\n",
       "ELKORN                 1\n",
       "CLARKSDALE             1\n",
       "ST JOSEPH              1\n",
       "KNOB NOSTER            1\n",
       "LAWSON                 1\n",
       "FORT LUPTON            1\n",
       "PRAIRIE VILAGE         1\n",
       "LAYFAYETTE             1\n",
       "FAIRWAY`               1\n",
       "LINWOOD                1\n",
       "WESTWOOD HILLS         1\n",
       "STAPLETON              1\n",
       "LAWRENCE               1\n",
       "DENVER,                1\n",
       "COLORADO SPR           1\n",
       "BOLCKOW                1\n",
       "RAYMORE                1\n",
       "LONGMONT               1\n",
       "FERDERICK              1\n",
       "ST. JOSEPH             1\n",
       "OLATHE                 1\n",
       "RED FEATHER LAKES      1\n",
       "FORTR COLLINS          1\n",
       "AULT                   1\n",
       "DEARBORN               1\n",
       "BERTHOUD               1\n",
       "PLATTEVILLE            1\n",
       "FORT COINS             1\n",
       "Name: City, Length: 147, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_info_df['City'] = project_info_df['City'].str.upper()\n",
    "\n",
    "project_info_df['City'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim #                 object\n",
       "Job #                   object\n",
       "Branch                  object\n",
       "City                    object\n",
       "Building Department     object\n",
       "Permit Req?             object\n",
       "Supplier Name           object\n",
       "Crew                    object\n",
       "Insurance Company       object\n",
       "Multi-rejected          object\n",
       "Scope Rejections       float64\n",
       "Change Orders          float64\n",
       "Labor Adjustments      float64\n",
       "Sup                     object\n",
       "Rep                     object\n",
       "FTA                     object\n",
       "BC                      object\n",
       "OB                      object\n",
       "GM                      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project_info_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow_table_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eagleview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Square Feet</th>\n",
       "      <th>Ridges</th>\n",
       "      <th>Hips</th>\n",
       "      <th>Valleys</th>\n",
       "      <th>Rakes</th>\n",
       "      <th>Eaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>555130806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.77</td>\n",
       "      <td>65</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>127</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0552723793CAT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.25</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>193</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4114306-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.36</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13981161-005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.35</td>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>185</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2825952810</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.26</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>120</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Claim #  Job #  Square Feet  Ridges  Hips  Valleys  Rakes  Eaves\n",
       "0      555130806    NaN        20.77      65    13       49    127    127\n",
       "1  0552723793CAT    NaN        27.25      93     0       69    193    157\n",
       "2     4114306-09    NaN        20.36      46     0        0    122    122\n",
       "3   13981161-005    NaN        27.35      93     0       70    185    121\n",
       "4     2825952810    NaN        17.26      71     0       19    120    108"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the sf to SQ, then applying it to the 'square feet' column\n",
    "roof_sq_converter = lambda x: x/100\n",
    "eagleview_table_df['Square Feet'] = eagleview_table_df['Square Feet'].apply(roof_sq_converter)\n",
    "\n",
    "\n",
    "\n",
    "eagleview_table_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rep Claim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Rep Claim: 2479\n",
      "Quantile: 15.0\n",
      "Cleaned Records: 2235\n",
      "Outlier Records: 244\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'rep claim days'\n",
    "rep_quantile = workflow_table_df['Rep Collecting Claim'].quantile(.90)\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "rep_claim_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting Claim'] >= 0) & (\n",
    "    workflow_table_df['Rep Collecting Claim'] <= rep_quantile), :]\n",
    "\n",
    "# creating a rep claim outlier df\n",
    "outlier_rep_claim_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting Claim'] < 0) | (\n",
    "    workflow_table_df['Rep Collecting Claim'] > rep_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Rep Claim: {workflow_table_df['Rep Collecting Claim'].count()}\")\n",
    "print(f\"Quantile: {rep_quantile}\")\n",
    "print(f\"Cleaned Records: {len(rep_claim_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_rep_claim_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Outlier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# outlier_rep_claim_df['Rep Collecting Claim'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Building Department</th>\n",
       "      <th>City</th>\n",
       "      <th>Rep Agreement Signed</th>\n",
       "      <th>Rep Claim Collected</th>\n",
       "      <th>Rep Collecting Claim</th>\n",
       "      <th>Claim Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00140067991A028</td>\n",
       "      <td>1938689</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denver</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>040357502</td>\n",
       "      <td>1938476</td>\n",
       "      <td>FCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fort collins</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001691605</td>\n",
       "      <td>1938472</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Westminster, City of (DEN)</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>020487835-7</td>\n",
       "      <td>1938470</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23255128-002</td>\n",
       "      <td>1938447</td>\n",
       "      <td>OMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Claim #    Job # Branch         Building Department          City  \\\n",
       "0  00140067991A028  1938689    DEN                         NaN        Denver   \n",
       "1        040357502  1938476    FCO                         NaN  fort collins   \n",
       "2      01001691605  1938472    DEN  Westminster, City of (DEN)   Westminster   \n",
       "3      020487835-7  1938470    DEN                         NaN   Westminster   \n",
       "4     23255128-002  1938447    OMA                         NaN         Omaha   \n",
       "\n",
       "  Rep Agreement Signed Rep Claim Collected  Rep Collecting Claim Claim Status  \n",
       "0           2019-07-18          2019-07-18                   0.0          NaN  \n",
       "1           2019-07-15          2019-07-15                   0.0          NaN  \n",
       "2           2019-07-15          2019-07-15                   0.0          NaN  \n",
       "3           2019-07-15          2019-07-15                   0.0          NaN  \n",
       "4           2019-07-15          2019-07-16                   1.0          NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information to be combined with the rep data from 'project_table_df'\n",
    "rep_claim_project_analysis_df = project_table_df[['Claim #', 'Job #','Claim Status','Rep Agreement Signed',\n",
    "                                                  'Rep Claim Collected']]\n",
    "\n",
    "# information to be combined with the rep data from 'project_info_df'\n",
    "rep_claim_info_analysis_df = project_info_df[['Claim #', 'Job #', 'Branch', \n",
    "                                              'City', 'Building Department',]]\n",
    "\n",
    "# information to be combined with the rep data from 'workflow_table_df'\n",
    "rep_claim_workflow_analysis_df = workflow_table_df[['Claim #', 'Rep Collecting Claim']]\n",
    "\n",
    "\n",
    "# merging all of the dfs together to prepare rep claim analysis\n",
    "rep_claim_analysis_df = rep_claim_project_analysis_df.merge(\n",
    "    rep_claim_info_analysis_df, on=[\"Claim #\", \"Job #\"]).merge(\n",
    "    rep_claim_workflow_analysis_df, on=['Claim #'])\n",
    "\n",
    "# organizing the df\n",
    "rep_claim_analysis_df = rep_claim_analysis_df[['Claim #','Job #','Branch',\n",
    "                                               'Building Department','City','Rep Agreement Signed',\n",
    "                                               'Rep Claim Collected','Rep Collecting Claim','Claim Status']]\n",
    "\n",
    "rep_claim_analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FTA Scope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with FTA Scope: 2015\n",
      "Quantile: 12.0\n",
      "Cleaned Records: 1813\n",
      "Outlier Records: 202\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'fta scope days'\n",
    "fta_quantile = workflow_table_df['FTA Completing Scope'].quantile(.90)\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "fta_scope_df = workflow_table_df.loc[(workflow_table_df['FTA Completing Scope'] >= 0) & (\n",
    "    workflow_table_df['FTA Completing Scope'] <= fta_quantile), :]\n",
    "\n",
    "# creating a fta scope outlier df\n",
    "outlier_fta_scope_df = workflow_table_df.loc[(workflow_table_df['FTA Completing Scope'] < 0) | (\n",
    "    workflow_table_df['FTA Completing Scope'] > fta_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with FTA Scope: {workflow_table_df['FTA Completing Scope'].count()}\")\n",
    "print(f\"Quantile: {fta_quantile}\")\n",
    "print(f\"Cleaned Records: {len(fta_scope_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_fta_scope_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Outlier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# outlier_fta_scope_df['FTA Completing Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    593\n",
       "True     276\n",
       "Name: Multi-rejected, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information to be combined with the rep data from 'project_table_df'\n",
    "fta_scope_project_analysis_df = project_table_df[['Claim #', 'Job #', 'Branch', \n",
    "                                                  'Claim Status', 'Rep Claim Collected', \n",
    "                                                  'FTA Scope Completed', 'FTA Scope Rejected']]\n",
    "\n",
    "# information to be combined with the rep data from 'project_info_df'\n",
    "fta_scope_info_analysis_df = project_info_df[['Claim #', 'Job #', \n",
    "                                              'City', 'Building Department','Multi-rejected',\n",
    "                                              'Scope Rejections']]\n",
    "\n",
    "# information to be combined with the rep data from 'workflow_table_df'\n",
    "fta_scope_workflow_analysis_df = workflow_table_df[['Claim #', 'FTA Completing Scope']]\n",
    "\n",
    "\n",
    "# merging all of the dfs together to prepare rep claim analysis\n",
    "fta_scope_analysis_df = fta_scope_project_analysis_df.merge(\n",
    "    fta_scope_info_analysis_df, on=[\"Claim #\", \"Job #\"]).merge(\n",
    "    fta_scope_workflow_analysis_df, on=['Claim #'])\n",
    "\n",
    "# organizing the df\n",
    "fta_scope_analysis_df = fta_scope_analysis_df[['Claim #','Job #','Branch',\n",
    "                                               'Building Department','City','Rep Claim Collected',\n",
    "                                               'FTA Scope Completed', 'FTA Scope Rejected','FTA Completing Scope',\n",
    "                                               'Scope Rejections', 'Multi-rejected','Claim Status']]\n",
    "\n",
    "\n",
    "fta_scope_analysis_df = fta_scope_analysis_df.loc[fta_scope_analysis_df['FTA Scope Completed'].notnull()==True,:]\n",
    "\n",
    "\n",
    "fta_scope_analysis_df[\"Multi-rejected\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Building Department</th>\n",
       "      <th>City</th>\n",
       "      <th>Rep Claim Collected</th>\n",
       "      <th>FTA Scope Completed</th>\n",
       "      <th>FTA Scope Rejected</th>\n",
       "      <th>FTA Completing Scope</th>\n",
       "      <th>Scope Rejections</th>\n",
       "      <th>Multi-rejected</th>\n",
       "      <th>Claim Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00140067991A028</td>\n",
       "      <td>1938689</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denver</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>040357502</td>\n",
       "      <td>1938476</td>\n",
       "      <td>FCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fort collins</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001691605</td>\n",
       "      <td>1938472</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Westminster, City of (DEN)</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>020487835-7</td>\n",
       "      <td>1938470</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23255128-002</td>\n",
       "      <td>1938447</td>\n",
       "      <td>OMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Claim #    Job # Branch         Building Department          City  \\\n",
       "0  00140067991A028  1938689    DEN                         NaN        Denver   \n",
       "1        040357502  1938476    FCO                         NaN  fort collins   \n",
       "2      01001691605  1938472    DEN  Westminster, City of (DEN)   Westminster   \n",
       "3      020487835-7  1938470    DEN                         NaN   Westminster   \n",
       "4     23255128-002  1938447    OMA                         NaN         Omaha   \n",
       "\n",
       "  Rep Claim Collected FTA Scope Completed FTA Scope Rejected  \\\n",
       "0          2019-07-18          2019-07-20         2019-07-23   \n",
       "1          2019-07-15          2019-07-22                NaT   \n",
       "2          2019-07-15          2019-07-17                NaT   \n",
       "3          2019-07-15          2019-07-16                NaT   \n",
       "4          2019-07-16          2019-07-17         2019-07-23   \n",
       "\n",
       "   FTA Completing Scope  Scope Rejections Multi-rejected Claim Status  \n",
       "0                   5.0               1.0          False          NaN  \n",
       "1                   7.0               NaN            NaN          NaN  \n",
       "2                   2.0               NaN            NaN          NaN  \n",
       "3                   1.0               NaN            NaN          NaN  \n",
       "4                   7.0               1.0          False          NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fta_scope_analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Estimate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Estimate: 1969\n",
      "Quantile: 2.0\n",
      "Cleaned Records: 1793\n",
      "Outlier Records: 176\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'rep claim days'\n",
    "bc_quantile = workflow_table_df['BC Completing Estimate'].quantile(.90)\n",
    "num_bc_estimates = workflow_table_df['BC Completing Estimate'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_estimate_df = workflow_table_df.loc[(workflow_table_df['BC Completing Estimate'] >= 0) & (\n",
    "    workflow_table_df['BC Completing Estimate'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc estimate outlier df\n",
    "outlier_bc_estimate_df = workflow_table_df.loc[(workflow_table_df['BC Completing Estimate'] < 0) | (\n",
    "    workflow_table_df['BC Completing Estimate'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Estimate: {workflow_table_df['BC Completing Estimate'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")\n",
    "print(f\"Cleaned Records: {len(bc_estimate_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_estimate_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3.0     116\n",
       " 4.0      21\n",
       " 5.0      11\n",
       " 6.0       7\n",
       " 10.0      3\n",
       " 7.0       3\n",
       " 8.0       3\n",
       "-1.0       2\n",
       " 12.0      1\n",
       "-4.0       1\n",
       " 17.0      1\n",
       " 14.0      1\n",
       " 13.0      1\n",
       " 9.0       1\n",
       "-7.0       1\n",
       " 23.0      1\n",
       "-2.0       1\n",
       "-3.0       1\n",
       "Name: BC Completing Estimate, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_estimate_df['BC Completing Estimate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OB Scope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with OB Scope: 1865\n",
      "Quantile: 6.0\n",
      "Cleaned Records: 1711\n",
      "Outlier Records: 154\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ob scoped days'\n",
    "ob_quantile = workflow_table_df['OB Completing Scope'].quantile(.90)\n",
    "num_ob_scopes = workflow_table_df['OB Completing Scope'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ob_scope_df = workflow_table_df.loc[(workflow_table_df['OB Completing Scope'] >= 0) & (\n",
    "    workflow_table_df['OB Completing Scope'] <= ob_quantile), :]\n",
    "\n",
    "# creating a ob scoped outlier df\n",
    "outlier_ob_scope_df = workflow_table_df.loc[(workflow_table_df['OB Completing Scope'] < 0) | (\n",
    "    workflow_table_df['OB Completing Scope'] > ob_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with OB Scope: {workflow_table_df['OB Completing Scope'].count()}\")\n",
    "print(f\"Quantile: {ob_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ob_scope_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ob_scope_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 7.0     59\n",
       " 8.0     22\n",
       " 10.0    13\n",
       " 9.0     11\n",
       "-1.0     11\n",
       " 11.0    11\n",
       " 12.0     8\n",
       " 13.0     4\n",
       "-4.0      3\n",
       "-2.0      2\n",
       " 16.0     1\n",
       " 25.0     1\n",
       " 17.0     1\n",
       " 15.0     1\n",
       "-34.0     1\n",
       "-7.0      1\n",
       " 87.0     1\n",
       " 14.0     1\n",
       "-5.0      1\n",
       " 49.0     1\n",
       "Name: OB Completing Scope, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ob_scope_df['OB Completing Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# will want to see what is causing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outlier_ob_scope_df.to_csv(\"data/outliers/ob_scope_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sup Submittal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Sup Submit: 1191\n",
      "Quantile: 22.0\n",
      "Cleaned Records: 1078\n",
      "Outlier Records: 113\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'sup submitted days'\n",
    "sup_quantile = workflow_table_df['Sup Submitting Job'].quantile(.90)\n",
    "num_sup_submits = workflow_table_df['Sup Submitting Job'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "sup_submit_df = workflow_table_df.loc[(workflow_table_df['Sup Submitting Job'] >= 0) & (\n",
    "    workflow_table_df['Sup Submitting Job'] <= sup_quantile), :]\n",
    "\n",
    "# creating a sup submitted outlier df\n",
    "outlier_sup_submit_df = workflow_table_df.loc[(workflow_table_df['Sup Submitting Job'] < 0) | (\n",
    "    workflow_table_df['Sup Submitting Job'] > sup_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Sup Submit: {workflow_table_df['Sup Submitting Job'].count()}\")\n",
    "print(f\"Quantile: {sup_quantile}\")\n",
    "print(f\"Cleaned Records: {len(sup_submit_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_sup_submit_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 23.0    13\n",
       " 27.0    10\n",
       " 33.0     8\n",
       " 34.0     7\n",
       " 24.0     6\n",
       " 38.0     5\n",
       " 37.0     4\n",
       " 26.0     4\n",
       " 28.0     3\n",
       " 29.0     3\n",
       " 56.0     3\n",
       " 40.0     3\n",
       " 39.0     3\n",
       " 35.0     3\n",
       " 31.0     3\n",
       " 43.0     3\n",
       " 25.0     3\n",
       " 30.0     2\n",
       "-2.0      2\n",
       " 41.0     2\n",
       "-4.0      2\n",
       " 42.0     2\n",
       " 36.0     2\n",
       " 51.0     2\n",
       " 45.0     2\n",
       " 46.0     2\n",
       " 44.0     1\n",
       " 32.0     1\n",
       " 50.0     1\n",
       " 61.0     1\n",
       " 49.0     1\n",
       " 62.0     1\n",
       " 48.0     1\n",
       "-5.0      1\n",
       " 60.0     1\n",
       "-10.0     1\n",
       " 66.0     1\n",
       "Name: Sup Submitting Job, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_sup_submit_df['Sup Submitting Job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Approval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Approval: 1118\n",
      "Quantile: 8.300000000000068\n",
      "Cleaned Records: 1003\n",
      "Outlier Records: 115\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc approved days'\n",
    "bc_quantile = workflow_table_df['BC Approving Job'].quantile(.90)\n",
    "num_bc_approvals = workflow_table_df['BC Approving Job'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_approval_df = workflow_table_df.loc[(workflow_table_df['BC Approving Job'] >= 0) & (\n",
    "    workflow_table_df['BC Approving Job'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc approved outlier df\n",
    "outlier_bc_approval_df = workflow_table_df.loc[(workflow_table_df['BC Approving Job'] < 0) | (\n",
    "    workflow_table_df['BC Approving Job'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Approval: {workflow_table_df['BC Approving Job'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")\n",
    "print(f\"Cleaned Records: {len(bc_approval_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_approval_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 13.0    15\n",
       " 9.0     14\n",
       " 12.0    13\n",
       " 11.0    12\n",
       " 20.0     8\n",
       " 19.0     7\n",
       " 14.0     5\n",
       " 26.0     5\n",
       " 10.0     4\n",
       " 17.0     4\n",
       " 21.0     4\n",
       " 25.0     4\n",
       " 18.0     3\n",
       " 16.0     3\n",
       " 23.0     2\n",
       " 15.0     2\n",
       " 27.0     1\n",
       " 41.0     1\n",
       " 35.0     1\n",
       "-11.0     1\n",
       " 39.0     1\n",
       " 29.0     1\n",
       "-13.0     1\n",
       " 32.0     1\n",
       "-4.0      1\n",
       " 46.0     1\n",
       "Name: BC Approving Job, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_approval_df['BC Approving Job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OB Create Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with OB Order: 1085\n",
      "Quantile: 5.0\n",
      "Cleaned Records: 990\n",
      "Outlier Records: 95\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ob created days'\n",
    "ob_quantile = workflow_table_df['OB Building Order'].quantile(.90)\n",
    "num_ob_orders = workflow_table_df['OB Building Order'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ob_order_df = workflow_table_df.loc[(workflow_table_df['OB Building Order'] >= 0) & (\n",
    "    workflow_table_df['OB Building Order'] <= ob_quantile), :]\n",
    "\n",
    "# creating a ob created outlier df\n",
    "outlier_ob_order_df = workflow_table_df.loc[(workflow_table_df['OB Building Order'] < 0) | (\n",
    "    workflow_table_df['OB Building Order'] > ob_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with OB Order: {workflow_table_df['OB Building Order'].count()}\")\n",
    "print(f\"Quantile: {ob_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ob_order_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ob_order_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 7.0     15\n",
       " 6.0     14\n",
       " 11.0    12\n",
       " 8.0      9\n",
       " 10.0     9\n",
       " 9.0      9\n",
       " 12.0     7\n",
       " 13.0     4\n",
       " 15.0     4\n",
       " 20.0     4\n",
       " 16.0     2\n",
       "-9.0      1\n",
       " 53.0     1\n",
       " 27.0     1\n",
       " 28.0     1\n",
       " 24.0     1\n",
       " 40.0     1\n",
       "Name: OB Building Order, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ob_order_df['OB Building Order'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GM Process Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with GM Processed Order: 884\n",
      "Quantile: 20.0\n",
      "Cleaned Records: 796\n",
      "Outlier Records: 88\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'gm processed days'\n",
    "gm_quantile = workflow_table_df['GM Processing Order'].quantile(.90)\n",
    "num_gm_orders = workflow_table_df['GM Processing Order'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "gm_order_df = workflow_table_df.loc[(workflow_table_df['GM Processing Order'] >= 0) & (\n",
    "    workflow_table_df['GM Processing Order'] <= gm_quantile), :]\n",
    "\n",
    "# creating a gm processed outlier df\n",
    "outlier_gm_order_df = workflow_table_df.loc[(workflow_table_df['GM Processing Order'] < 0) | (\n",
    "    workflow_table_df['GM Processing Order'] > gm_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with GM Processed Order: {workflow_table_df['GM Processing Order'].count()}\")\n",
    "print(f\"Quantile: {gm_quantile}\")\n",
    "print(f\"Cleaned Records: {len(gm_order_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_gm_order_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 21.0    12\n",
       " 22.0     9\n",
       " 29.0     8\n",
       " 27.0     7\n",
       " 28.0     7\n",
       " 24.0     7\n",
       " 30.0     5\n",
       " 23.0     4\n",
       " 38.0     3\n",
       " 34.0     3\n",
       " 36.0     3\n",
       " 25.0     2\n",
       " 41.0     2\n",
       " 26.0     2\n",
       " 42.0     2\n",
       " 47.0     1\n",
       " 60.0     1\n",
       "-7.0      1\n",
       " 40.0     1\n",
       " 35.0     1\n",
       " 55.0     1\n",
       " 46.0     1\n",
       " 63.0     1\n",
       " 54.0     1\n",
       " 37.0     1\n",
       " 43.0     1\n",
       " 32.0     1\n",
       "Name: GM Processing Order, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_gm_order_df['GM Processing Order'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# will want to determine what is causing the outliers\n",
    "outlier_gm_order_df.to_csv(\"data_copy/outliers/gm_order_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PA Process OA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with PA OA Processed: 827\n",
      "Quantile: 3.0\n",
      "Cleaned Records: 756\n",
      "Outlier Records: 71\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'pa oa processeddays'\n",
    "pa_quantile = workflow_table_df['PA Processing OA'].quantile(.90)\n",
    "num_pa_oa_processed = workflow_table_df['PA Processing OA'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "pa_processed_oa_df = workflow_table_df.loc[(workflow_table_df['PA Processing OA'] >= 0) & (\n",
    "    workflow_table_df['PA Processing OA'] <= pa_quantile), :]\n",
    "\n",
    "# creating a pa oa processedoutlier df\n",
    "outlier_pa_processed_oa_df = workflow_table_df.loc[(workflow_table_df['PA Processing OA'] < 0) | (\n",
    "    workflow_table_df['PA Processing OA'] > pa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with PA OA Processed: {workflow_table_df['PA Processing OA'].count()}\")\n",
    "print(f\"Quantile: {pa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(pa_processed_oa_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_pa_processed_oa_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0     24\n",
       " 5.0     20\n",
       " 6.0      7\n",
       " 10.0     4\n",
       " 7.0      2\n",
       " 11.0     2\n",
       " 8.0      2\n",
       " 30.0     1\n",
       " 17.0     1\n",
       " 12.0     1\n",
       "-10.0     1\n",
       " 20.0     1\n",
       " 14.0     1\n",
       " 15.0     1\n",
       "-1.0      1\n",
       " 42.0     1\n",
       " 18.0     1\n",
       "Name: PA Processing OA, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_pa_processed_oa_df['PA Processing OA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PA Invoicing OA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with PA OA Invoiced: 714\n",
      "Quantile: 8.0\n",
      "Cleaned Records: 668\n",
      "Outlier Records: 46\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'pa oa invoiceddays'\n",
    "pa_quantile = workflow_table_df['PA Invoicing OA'].quantile(.90)\n",
    "num_pa_oa_invoiced = workflow_table_df['PA Invoicing OA'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "pa_invoiced_oa_df = workflow_table_df.loc[(workflow_table_df['PA Invoicing OA'] >= 0) & (\n",
    "    workflow_table_df['PA Invoicing OA'] <= pa_quantile), :]\n",
    "\n",
    "# creating a pa oa invoicedoutlier df\n",
    "outlier_pa_invoiced_oa_df = workflow_table_df.loc[(workflow_table_df['PA Invoicing OA'] < 0) | (\n",
    "    workflow_table_df['PA Invoicing OA'] > pa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with PA OA Invoiced: {workflow_table_df['PA Invoicing OA'].count()}\")\n",
    "print(f\"Quantile: {pa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(pa_invoiced_oa_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_pa_invoiced_oa_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0    14\n",
       "9.0     10\n",
       "10.0     4\n",
       "15.0     3\n",
       "12.0     3\n",
       "19.0     3\n",
       "13.0     2\n",
       "33.0     1\n",
       "21.0     1\n",
       "20.0     1\n",
       "18.0     1\n",
       "14.0     1\n",
       "16.0     1\n",
       "28.0     1\n",
       "Name: PA Invoicing OA, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_pa_invoiced_oa_df['PA Invoicing OA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_pa_invoiced_oa_df.to_csv(\"data_copy/outliers/pa_invoiced_oa_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GM Approving for Inspection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with GM Approved for Inspection: 645\n",
      "Quantile: 3.0\n",
      "Cleaned Records: 587\n",
      "Outlier Records: 58\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'gm approved for inspection days'\n",
    "gm_quantile = workflow_table_df['GM Approving for Inspection'].quantile(.90)\n",
    "num_gm_approved_inspection = workflow_table_df['GM Approving for Inspection'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "gm_approved_inspection_df = workflow_table_df.loc[(workflow_table_df['GM Approving for Inspection'] >= 0) & (\n",
    "    workflow_table_df['GM Approving for Inspection'] <= gm_quantile), :]\n",
    "\n",
    "# creating a gm approved for inspection outlier df\n",
    "outlier_gm_approved_inspection_df = workflow_table_df.loc[(workflow_table_df['GM Approving for Inspection'] < 0) | (\n",
    "    workflow_table_df['GM Approving for Inspection'] > gm_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with GM Approved for Inspection: {workflow_table_df['GM Approving for Inspection'].count()}\")\n",
    "print(f\"Quantile: {gm_quantile}\")\n",
    "print(f\"Cleaned Records: {len(gm_approved_inspection_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_gm_approved_inspection_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0     26\n",
       "5.0     17\n",
       "6.0     13\n",
       "30.0     1\n",
       "8.0      1\n",
       "Name: GM Approving for Inspection, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_gm_approved_inspection_df['GM Approving for Inspection'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_gm_approved_inspection_df.to_csv(\"data_copy/outliers/gm_approved_inspection_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RA Requesting Inspection Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with RA Requested Inspection: 280\n",
      "Quantile: 18.0\n",
      "Cleaned Records: 254\n",
      "Outlier Records: 26\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ra requesting inspection days'\n",
    "ra_quantile = workflow_table_df['RA Requesting Inspection'].quantile(.90)\n",
    "num_ra_requested = workflow_table_df['RA Requesting Inspection'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ra_requested_inspection_df = workflow_table_df.loc[(workflow_table_df['RA Requesting Inspection'] >= 0) & (\n",
    "    workflow_table_df['RA Requesting Inspection'] <= ra_quantile), :]\n",
    "\n",
    "# creating a ra requesting inspection outlier df\n",
    "outlier_ra_requested_inspection_df = workflow_table_df.loc[(workflow_table_df['RA Requesting Inspection'] < 0) | (\n",
    "    workflow_table_df['RA Requesting Inspection'] > ra_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with RA Requested Inspection: {workflow_table_df['RA Requesting Inspection'].count()}\")\n",
    "print(f\"Quantile: {ra_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ra_requested_inspection_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ra_requested_inspection_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0    4\n",
       "20.0    3\n",
       "25.0    3\n",
       "27.0    2\n",
       "22.0    2\n",
       "26.0    1\n",
       "21.0    1\n",
       "42.0    1\n",
       "36.0    1\n",
       "45.0    1\n",
       "67.0    1\n",
       "24.0    1\n",
       "28.0    1\n",
       "61.0    1\n",
       "47.0    1\n",
       "31.0    1\n",
       "41.0    1\n",
       "Name: RA Requesting Inspection, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ra_requested_inspection_df['RA Requesting Inspection'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rep Collecting COC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Rep COC Collected: 615\n",
      "Quantile: 15.0\n",
      "Cleaned Records: 556\n",
      "Outlier Records: 59\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'rep collect coc days'\n",
    "rep_quantile = workflow_table_df['Rep Collecting COC'].quantile(.90)\n",
    "num_rep_collected = workflow_table_df['Rep Collecting COC'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "rep_collected_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting COC'] >= 0) & (\n",
    "    workflow_table_df['Rep Collecting COC'] <= rep_quantile), :]\n",
    "\n",
    "# creating a rep collect coc outlier df\n",
    "outlier_rep_collected_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting COC'] < 0) | (\n",
    "    workflow_table_df['Rep Collecting COC'] > rep_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Rep COC Collected: {workflow_table_df['Rep Collecting COC'].count()}\")\n",
    "print(f\"Quantile: {rep_quantile}\")\n",
    "print(f\"Cleaned Records: {len(rep_collected_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_rep_collected_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0    10\n",
       "20.0     6\n",
       "19.0     4\n",
       "23.0     4\n",
       "17.0     4\n",
       "24.0     3\n",
       "22.0     3\n",
       "35.0     2\n",
       "21.0     2\n",
       "26.0     2\n",
       "33.0     2\n",
       "18.0     2\n",
       "37.0     2\n",
       "28.0     2\n",
       "29.0     1\n",
       "47.0     1\n",
       "43.0     1\n",
       "25.0     1\n",
       "62.0     1\n",
       "46.0     1\n",
       "34.0     1\n",
       "50.0     1\n",
       "32.0     1\n",
       "49.0     1\n",
       "30.0     1\n",
       "Name: Rep Collecting COC, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_rep_collected_df['Rep Collecting COC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_rep_collected_df.to_csv(\"data_copy/outliers/rep_collected_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SA Uploading Docs Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with SA Docs Uploaded: 522\n",
      "Quantile: 16.0\n",
      "Cleaned Records: 473\n",
      "Outlier Records: 49\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'sa uploaded days'\n",
    "sa_quantile = workflow_table_df['SA Uploading Docs'].quantile(.90)\n",
    "num_sa_uploaded = workflow_table_df['SA Uploading Docs'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "sa_uploaded_df = workflow_table_df.loc[(workflow_table_df['SA Uploading Docs'] >= 0) & (\n",
    "    workflow_table_df['SA Uploading Docs'] <= sa_quantile), :]\n",
    "\n",
    "# creating a sa uploaded outlier df\n",
    "outlier_sa_uploaded_df = workflow_table_df.loc[(workflow_table_df['SA Uploading Docs'] < 0) | (\n",
    "    workflow_table_df['SA Uploading Docs'] > sa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with SA Docs Uploaded: {workflow_table_df['SA Uploading Docs'].count()}\")\n",
    "print(f\"Quantile: {sa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(sa_uploaded_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_sa_uploaded_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0    8\n",
       "26.0    5\n",
       "19.0    4\n",
       "25.0    4\n",
       "32.0    3\n",
       "24.0    3\n",
       "18.0    3\n",
       "27.0    3\n",
       "28.0    2\n",
       "37.0    2\n",
       "23.0    2\n",
       "20.0    2\n",
       "17.0    2\n",
       "22.0    1\n",
       "54.0    1\n",
       "33.0    1\n",
       "29.0    1\n",
       "44.0    1\n",
       "71.0    1\n",
       "Name: SA Uploading Docs, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_sa_uploaded_df['SA Uploading Docs'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BC Invoicing Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Project Invoiced: 464\n",
      "Quantile: 9.0\n",
      "Cleaned Records: 422\n",
      "Outlier Records: 42\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc invoiced days'\n",
    "bc_quantile = workflow_table_df['BC Invoicing Project'].quantile(.90)\n",
    "num_bc_invoiced = workflow_table_df['BC Invoicing Project'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_invoiced_df = workflow_table_df.loc[(workflow_table_df['BC Invoicing Project'] >= 0) & (\n",
    "    workflow_table_df['BC Invoicing Project'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc invoiced outlier df\n",
    "outlier_bc_invoiced_df = workflow_table_df.loc[(workflow_table_df['BC Invoicing Project'] < 0) | (\n",
    "    workflow_table_df['BC Invoicing Project'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Project Invoiced: {workflow_table_df['BC Invoicing Project'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")      \n",
    "print(f\"Cleaned Records: {len(bc_invoiced_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_invoiced_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0    7\n",
       "15.0    6\n",
       "10.0    6\n",
       "12.0    5\n",
       "11.0    5\n",
       "16.0    3\n",
       "17.0    3\n",
       "13.0    3\n",
       "18.0    2\n",
       "21.0    1\n",
       "20.0    1\n",
       "Name: BC Invoicing Project, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_invoiced_df['BC Invoicing Project'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BC Closed Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Project Closed: 237\n",
      "Quantile: 41.0\n",
      "Cleaned Records: 216\n",
      "Outlier Records: 21\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc closed days'\n",
    "bc_quantile = workflow_table_df['BC Closed Project'].quantile(.90)\n",
    "num_bc_closed = workflow_table_df['BC Closed Project'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_closed_df = workflow_table_df.loc[(workflow_table_df['BC Closed Project'] >= 0) & (\n",
    "    workflow_table_df['BC Closed Project'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc closed outlier df\n",
    "outlier_bc_closed_df = workflow_table_df.loc[(workflow_table_df['BC Closed Project'] < 0) | (\n",
    "    workflow_table_df['BC Closed Project'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Project Closed: {workflow_table_df['BC Closed Project'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")      \n",
    "print(f\"Cleaned Records: {len(bc_closed_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_closed_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.0    2\n",
       "49.0    2\n",
       "51.0    2\n",
       "43.0    2\n",
       "47.0    2\n",
       "48.0    1\n",
       "69.0    1\n",
       "78.0    1\n",
       "67.0    1\n",
       "63.0    1\n",
       "70.0    1\n",
       "77.0    1\n",
       "71.0    1\n",
       "68.0    1\n",
       "50.0    1\n",
       "42.0    1\n",
       "Name: BC Closed Project, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_closed_df['BC Closed Project'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.521px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "695.208px",
    "left": "830px",
    "right": "20px",
    "top": "120px",
    "width": "314.774px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
