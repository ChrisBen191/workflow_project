{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this allows the 'data_prep' file to be ran before this file tries to bring in those datasets\n",
    "os.system(\"python data_prep.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the 'project table' data\n",
    "project_table_data = \"./data/cleaned_data/project_table.csv\"\n",
    "project_table_df = pd.read_csv(\n",
    "    project_table_data, dtype={\n",
    "        'Claim #': str,\n",
    "        'Job #': str,\n",
    "        'Branch':str,\n",
    "        'Claim Status':str},\n",
    "    parse_dates=[\n",
    "        'Rep Agreement Signed', 'Rep Claim Collected','FTA Scope Completed',\n",
    "        'FTA Scope Rejected', 'BC Estimate Completed','OB Scope Completed',\n",
    "        'Sup Job Submitted', 'BC Approved for Production', 'OB Order Built',\n",
    "        'GM Order Processed', 'PA Permit Applied', 'PA Permit Processed',\n",
    "        'PA OA Processed', 'PA OA Invoiced', 'PA Notify of Delivery',\n",
    "        'PA Notify of Start', 'Delivery Date', 'Roof Start',\n",
    "        'Roof End', 'GM Approved for Inspection', 'GM Change Order Date',\n",
    "        'GM Labor Adjustment Date', 'RA Inspection Requested', 'RA Inspection Processed', \n",
    "        'Rep COC Collected', 'SA Job Docs Uploaded', 'BC Project Invoiced','BC Project Closed'])\n",
    "\n",
    "# imports the 'project information' data\n",
    "project_info_data = \"./data/cleaned_data/project_info_table.csv\"\n",
    "project_info_df = pd.read_csv(project_info_data, dtype={\n",
    "    'Claim #':str, 'Job #':str, 'Branch':str, 'City':str, 'Building Department':str,\n",
    "    'Permit Req?':str, 'Supplier Name':str, 'Crew':str, 'Insurance Company':str,\n",
    "    'Multi-rejected':str, 'Scope Rejections':str, 'Change Orders':str,'Labor Adjustments':str,\n",
    "    'Sup':str, 'Rep':str, 'FTA':str, 'BC':str, 'OB':str, 'GM':str})\n",
    "\n",
    "# imports 'workflow table' data\n",
    "workflow_table_data = \"./data/cleaned_data/workflow_table.csv\"\n",
    "workflow_table_df = pd.read_csv(workflow_table_data)\n",
    "\n",
    "# imports the 'eagleview table' data\n",
    "eagleview_table_data = \"./data/eagleview_analysis.csv\"\n",
    "eagleview_table_df = pd.read_csv(eagleview_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(project_table_df.columns)\n",
    "# print(project_info_df.columns)\n",
    "# print(workflow_table_df.columns)\n",
    "# print(eagleview_table_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separating the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Branch</th>\n",
       "      <th>City</th>\n",
       "      <th>Building Department</th>\n",
       "      <th>Permit Req?</th>\n",
       "      <th>Supplier Name</th>\n",
       "      <th>Crew</th>\n",
       "      <th>Insurance Company</th>\n",
       "      <th>Multi-rejected</th>\n",
       "      <th>Scope Rejections</th>\n",
       "      <th>Change Orders</th>\n",
       "      <th>Labor Adjustments</th>\n",
       "      <th>Sup</th>\n",
       "      <th>Rep</th>\n",
       "      <th>FTA</th>\n",
       "      <th>BC</th>\n",
       "      <th>OB</th>\n",
       "      <th>GM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>006253424</td>\n",
       "      <td>1938990</td>\n",
       "      <td>FCO</td>\n",
       "      <td>FORT COLLINS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USAA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jasper Gantick</td>\n",
       "      <td>Tyler Lehnert</td>\n",
       "      <td>Jacob Diebold</td>\n",
       "      <td>Marc DeBellis</td>\n",
       "      <td>Ryan Butacan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01001634265</td>\n",
       "      <td>1938839</td>\n",
       "      <td>KCI</td>\n",
       "      <td>KANSAS CITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matthew Hoover</td>\n",
       "      <td>Stuart Kolpin (Intern)</td>\n",
       "      <td>Joey Franke</td>\n",
       "      <td>Jon Tousley</td>\n",
       "      <td>Ryan Butacan</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019W78</td>\n",
       "      <td>1938755</td>\n",
       "      <td>KCI</td>\n",
       "      <td>AGENCY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Buchanan County Mutual Insurance Company</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aaron Cohen</td>\n",
       "      <td>Brett Nichols (Intern)</td>\n",
       "      <td>Kelly Stoker</td>\n",
       "      <td>Patrick Donahue</td>\n",
       "      <td>Cody Toliver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01001694638</td>\n",
       "      <td>1938738</td>\n",
       "      <td>KCI</td>\n",
       "      <td>PRAIRIE VILLAGE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>American Family</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eric Hoffman</td>\n",
       "      <td>Marilee Rose</td>\n",
       "      <td>Keegan Carter</td>\n",
       "      <td>Robert Castillo</td>\n",
       "      <td>Megan Haffner</td>\n",
       "      <td>Glen Stockdall Jr.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00140067991A028</td>\n",
       "      <td>1938689</td>\n",
       "      <td>DEN</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>USAA</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Derick DeCesare</td>\n",
       "      <td>Carter Mott (Intern)</td>\n",
       "      <td>Andrew Roberts</td>\n",
       "      <td>Nolan King</td>\n",
       "      <td>Cody Toliver</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Claim #    Job # Branch             City Building Department  \\\n",
       "0        006253424  1938990    FCO     FORT COLLINS                 NaN   \n",
       "1      01001634265  1938839    KCI      KANSAS CITY                 NaN   \n",
       "2          2019W78  1938755    KCI           AGENCY                 NaN   \n",
       "3      01001694638  1938738    KCI  PRAIRIE VILLAGE                 NaN   \n",
       "4  00140067991A028  1938689    DEN           DENVER                 NaN   \n",
       "\n",
       "  Permit Req? Supplier Name Crew                         Insurance Company  \\\n",
       "0         NaN           NaN  NaN                                      USAA   \n",
       "1         NaN           NaN  NaN                           American Family   \n",
       "2         NaN           NaN  NaN  Buchanan County Mutual Insurance Company   \n",
       "3         NaN           NaN  NaN                           American Family   \n",
       "4         NaN           NaN  NaN                                      USAA   \n",
       "\n",
       "  Multi-rejected Scope Rejections Change Orders Labor Adjustments  \\\n",
       "0            NaN              NaN           NaN               NaN   \n",
       "1            NaN              NaN           NaN               NaN   \n",
       "2            NaN              NaN           NaN               NaN   \n",
       "3            NaN              NaN           NaN               NaN   \n",
       "4          False              1.0           NaN               NaN   \n",
       "\n",
       "               Sup                     Rep             FTA               BC  \\\n",
       "0   Jasper Gantick           Tyler Lehnert   Jacob Diebold    Marc DeBellis   \n",
       "1   Matthew Hoover  Stuart Kolpin (Intern)     Joey Franke      Jon Tousley   \n",
       "2      Aaron Cohen  Brett Nichols (Intern)    Kelly Stoker  Patrick Donahue   \n",
       "3     Eric Hoffman            Marilee Rose   Keegan Carter  Robert Castillo   \n",
       "4  Derick DeCesare    Carter Mott (Intern)  Andrew Roberts       Nolan King   \n",
       "\n",
       "              OB                  GM  \n",
       "0   Ryan Butacan                 NaN  \n",
       "1   Ryan Butacan                 NaN  \n",
       "2   Cody Toliver                 NaN  \n",
       "3  Megan Haffner  Glen Stockdall Jr.  \n",
       "4   Cody Toliver                 NaN  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# due to manual 'city' field, city is incorrectly spelled or off on capitalization\n",
    "project_info_df['City'] = project_info_df['City'].str.upper()\n",
    "project_info_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eagleview Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Square Feet</th>\n",
       "      <th>Ridges</th>\n",
       "      <th>Hips</th>\n",
       "      <th>Valleys</th>\n",
       "      <th>Rakes</th>\n",
       "      <th>Eaves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1405695</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.96</td>\n",
       "      <td>201.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>310.0</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00825102185</td>\n",
       "      <td>1934386.0</td>\n",
       "      <td>35.52</td>\n",
       "      <td>49.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3011775484</td>\n",
       "      <td>1934497.0</td>\n",
       "      <td>29.98</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>118.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3011771813</td>\n",
       "      <td>1934612.0</td>\n",
       "      <td>28.21</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>333036-GI</td>\n",
       "      <td>1934980.0</td>\n",
       "      <td>21.22</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Claim #      Job #  Square Feet  Ridges   Hips  Valleys  Rakes  Eaves\n",
       "0      1405695        NaN        59.96   201.0    5.0    190.0  310.0  335.0\n",
       "1  00825102185  1934386.0        35.52    49.0  176.0     91.0   50.0  225.0\n",
       "2   3011775484  1934497.0        29.98   109.0    0.0     76.0  181.0  118.0\n",
       "3   3011771813  1934612.0        28.21    93.0    0.0     57.0  129.0  115.0\n",
       "4    333036-GI  1934980.0        21.22    93.0    0.0     68.0  157.0  142.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the sf to SQ, then applying it to the 'square feet' column\n",
    "roof_sq_converter = lambda x: x/100\n",
    "eagleview_table_df['Square Feet'] = eagleview_table_df['Square Feet'].apply(roof_sq_converter)\n",
    "\n",
    "\n",
    "\n",
    "eagleview_table_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rep Claim Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Rep Claim: 2589\n",
      "Quantile: 15.0\n",
      "Cleaned Records: 2334\n",
      "Outlier Records: 255\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'rep claim days'\n",
    "rep_quantile = workflow_table_df['Rep Collecting Claim'].quantile(.90)\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "rep_claim_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting Claim'] >= 0) & (\n",
    "    workflow_table_df['Rep Collecting Claim'] <= rep_quantile), :]\n",
    "\n",
    "# creating a rep claim outlier df\n",
    "outlier_rep_claim_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting Claim'] < 0) | (\n",
    "    workflow_table_df['Rep Collecting Claim'] > rep_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Rep Claim: {workflow_table_df['Rep Collecting Claim'].count()}\")\n",
    "print(f\"Quantile: {rep_quantile}\")\n",
    "print(f\"Cleaned Records: {len(rep_claim_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_rep_claim_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier_rep_claim_df['Rep Collecting Claim'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information to be combined with the rep data from 'project_table_df'\n",
    "rep_claim_project_analysis_df = project_table_df[['Claim #', 'Job #','Claim Status','Rep Agreement Signed',\n",
    "                                                  'Rep Claim Collected', 'FTA Scope Completed']]\n",
    "\n",
    "# information to be combined with the rep data from 'project_info_df'\n",
    "rep_claim_info_analysis_df = project_info_df[['Claim #', 'Job #', 'Branch', \n",
    "                                              'City', 'Building Department',]]\n",
    "\n",
    "# information to be combined with the rep data from 'workflow_table_df'\n",
    "rep_claim_workflow_analysis_df = workflow_table_df[['Claim #', 'Rep Collecting Claim']]\n",
    "\n",
    "\n",
    "# merging all of the dfs together to prepare rep claim analysis\n",
    "rep_claim_analysis_df = rep_claim_project_analysis_df.merge(\n",
    "    rep_claim_info_analysis_df, on=[\"Claim #\", \"Job #\"]).merge(\n",
    "    rep_claim_workflow_analysis_df, on=['Claim #'])\n",
    "\n",
    "# organizing the df\n",
    "rep_claim_analysis_df = rep_claim_analysis_df[['Claim #','Job #','Branch',\n",
    "                                               'Building Department','City',\n",
    "                                               'Rep Agreement Signed','Rep Claim Collected',\n",
    "                                               'Rep Collecting Claim','FTA Scope Completed','Claim Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "1009\n",
      "328\n",
      "673\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'DEN', :]))\n",
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'FCO', :]))\n",
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'COS', :]))\n",
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'KCI', :]))\n",
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'OMA', :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Claims Collected by Reps': 378, 'Average Days to Collect': 7.52}\n",
      "{'Claims Collected by Reps': 1009, 'Average Days to Collect': 3.86}\n",
      "{'Claims Collected by Reps': 328, 'Average Days to Collect': 7.63}\n",
      "{'Claims Collected by Reps': 673, 'Average Days to Collect': 7.64}\n",
      "{'Claims Collected by Reps': 226, 'Average Days to Collect': 9.9}\n"
     ]
    }
   ],
   "source": [
    "# created a 'branches' list to iterate over\n",
    "branches = ['DEN', 'FCO', 'COS', 'KCI', 'OMA' ]\n",
    "\n",
    "den_workflow_dict = {}\n",
    "fco_workflow_dict = {}\n",
    "cos_workflow_dict = {}\n",
    "kci_workflow_dict = {}\n",
    "oma_workflow_dict = {}\n",
    "\n",
    "for branch in branches:\n",
    "    \n",
    "    # separating the df into branches according to the 'branches' list\n",
    "    branch_rep_claim_analysis = rep_claim_analysis_df.loc[rep_claim_analysis_df['Branch'] == branch, :]\n",
    "    \n",
    "    # determining how many claim #s have been collected, 'dead' or not\n",
    "    rep_claim_collected_count = branch_rep_claim_analysis['Rep Claim Collected'].count()\n",
    "    \n",
    "    # determining the average amount of days to collect claim, 'dead' or not\n",
    "    rep_claim_collected_avg_days = round(branch_rep_claim_analysis['Rep Collecting Claim'].mean(), 2)\n",
    "    \n",
    "    # determing the count of 'dead' jobs per branch; provide insight on jobs that were actually marked 'dead' \n",
    "    # at this stage in the workflow (never got FTA Scoped)\n",
    "    rep_claims_dead_analysis = branch_rep_claim_analysis.loc[(branch_rep_claim_analysis['Claim Status'] == 'Dead' ) & (branch_rep_claim_analysis['FTA Scope Completed'].isnull() == True), : ]\n",
    "    rep_claim_dead_count = rep_claims_dead_analysis['Claim Status'].count()\n",
    "    \n",
    "    # iterating over each city in the 'branch' to better understand project concentration\n",
    "    city_list = branch_rep_claim_analysis['City'].unique()\n",
    "    \n",
    "    for city in city_list:\n",
    "       \n",
    "        # separating the 'branches' df into a smaller 'city' df\n",
    "        city_rep_claim_analysis = branch_rep_claim_analysis.loc[ branch_rep_claim_analysis['City'] == city, :]\n",
    "        \n",
    "        # determining how many claim #s have been collected in each city\n",
    "        city_rep_claim_collected_count = city_rep_claim_analysis['Rep Claim Collected'].count()\n",
    "        \n",
    "        # determining the average amount of days to collect claim in each city\n",
    "        city_rep_claim_collected_avg_days = round(city_rep_claim_analysis['Rep Collecting Claim'].mean(), 2)\n",
    "        \n",
    "    if branch == 'DEN':\n",
    "        \n",
    "        # update the 'den' dictionary\n",
    "        den_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])\n",
    "    \n",
    "    elif branch == 'FCO':\n",
    "        \n",
    "        # update the 'fco' dictionary\n",
    "        fco_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])\n",
    "\n",
    "    elif branch == 'COS':\n",
    "        \n",
    "        # update the 'cos' dictionary\n",
    "        cos_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])\n",
    "    \n",
    "    elif branch == 'KCI':\n",
    "        \n",
    "        # update the 'kci' dictionary\n",
    "        kci_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])        \n",
    "        \n",
    "    else:\n",
    "        # update the 'oma' dictionary\n",
    "        oma_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])\n",
    "\n",
    "print(den_workflow_dict)\n",
    "print(fco_workflow_dict)\n",
    "print(cos_workflow_dict)\n",
    "print(kci_workflow_dict)\n",
    "print(oma_workflow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Building Department</th>\n",
       "      <th>City</th>\n",
       "      <th>Rep Agreement Signed</th>\n",
       "      <th>Rep Claim Collected</th>\n",
       "      <th>Rep Collecting Claim</th>\n",
       "      <th>FTA Scope Completed</th>\n",
       "      <th>Claim Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>300-0241517-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LITTLETON</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>01001445976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LONGMONT</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>3012670962-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>ICK2981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LITTLETON</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>040054040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>300-122-067-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LITTLETON</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>069028C70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>3012794091-1-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEENESBURG</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Claim # Job # Branch Building Department        City  \\\n",
       "1287  300-0241517-2019   NaN    DEN                 NaN   LITTLETON   \n",
       "1338       01001445976   NaN    DEN                 NaN    LONGMONT   \n",
       "1344      3012670962-1   NaN    DEN                 NaN      DENVER   \n",
       "1773           ICK2981   NaN    DEN                 NaN   LITTLETON   \n",
       "1791         040054040   NaN    DEN                 NaN      DENVER   \n",
       "1910  300-122-067-2019   NaN    DEN                 NaN   LITTLETON   \n",
       "1937         069028C70   NaN    DEN                 NaN      DENVER   \n",
       "1980    3012794091-1-1   NaN    DEN                 NaN  KEENESBURG   \n",
       "\n",
       "     Rep Agreement Signed Rep Claim Collected  Rep Collecting Claim  \\\n",
       "1287           2019-07-18          2019-07-19                   1.0   \n",
       "1338           2019-04-18          2019-05-01                  13.0   \n",
       "1344           2019-04-18          2019-06-19                  62.0   \n",
       "1773           2019-03-20          2019-03-28                   8.0   \n",
       "1791           2019-05-30          2019-06-13                  14.0   \n",
       "1910           2019-04-25          2019-05-06                  11.0   \n",
       "1937           2019-05-30          2019-07-01                  32.0   \n",
       "1980           2019-06-11          2019-06-25                  14.0   \n",
       "\n",
       "     FTA Scope Completed Claim Status  \n",
       "1287                 NaT         Dead  \n",
       "1338                 NaT         Dead  \n",
       "1344                 NaT         Dead  \n",
       "1773                 NaT         Dead  \n",
       "1791                 NaT         Dead  \n",
       "1910                 NaT         Dead  \n",
       "1937                 NaT         Dead  \n",
       "1980                 NaT         Dead  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating the df into 'DEN'es according to the ''DEN'es' list\n",
    "branch_rep_claim_analysis = rep_claim_analysis_df.loc[rep_claim_analysis_df['Branch'] == 'DEN', :]\n",
    "\n",
    "# determining how many claim #s have been collected, 'dead' or not\n",
    "rep_claim_collected_count = branch_rep_claim_analysis['Rep Claim Collected'].count()\n",
    "\n",
    "# determining the average amount of days to collect claim, 'dead' or not\n",
    "rep_claim_collected_avg_days = round(branch_rep_claim_analysis['Rep Collecting Claim'].mean(), 2)\n",
    "\n",
    "# determing the count of 'dead' jobs per 'DEN'\n",
    "\n",
    "rep_claims_dead_analysis = branch_rep_claim_analysis.loc[(branch_rep_claim_analysis['Claim Status'] == 'Dead' ) & (branch_rep_claim_analysis['FTA Scope Completed'].isnull() == True), : ]\n",
    "\n",
    "# rep_claims_dead_analysis = (branch_rep_claim_analysis.loc[(branch_rep_claim_analysis['Claim Status'] == 'Dead') & \n",
    "#                                                           (branch_rep_claim_analysis['FTA Scope Completed'].isnull()) == True), :])\n",
    "\n",
    "# rep_claim_dead_count = rep_claims_dead_analysis['Claim Status'].count()\n",
    "\n",
    "rep_claims_dead_analysis.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FTA Scope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with FTA Scope: 2015\n",
      "Quantile: 12.0\n",
      "Cleaned Records: 1813\n",
      "Outlier Records: 202\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'fta scope days'\n",
    "fta_quantile = workflow_table_df['FTA Completing Scope'].quantile(.90)\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "fta_scope_df = workflow_table_df.loc[(workflow_table_df['FTA Completing Scope'] >= 0) & (\n",
    "    workflow_table_df['FTA Completing Scope'] <= fta_quantile), :]\n",
    "\n",
    "# creating a fta scope outlier df\n",
    "outlier_fta_scope_df = workflow_table_df.loc[(workflow_table_df['FTA Completing Scope'] < 0) | (\n",
    "    workflow_table_df['FTA Completing Scope'] > fta_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with FTA Scope: {workflow_table_df['FTA Completing Scope'].count()}\")\n",
    "print(f\"Quantile: {fta_quantile}\")\n",
    "print(f\"Cleaned Records: {len(fta_scope_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_fta_scope_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Outlier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# outlier_fta_scope_df['FTA Completing Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    593\n",
       "True     276\n",
       "Name: Multi-rejected, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information to be combined with the rep data from 'project_table_df'\n",
    "fta_scope_project_analysis_df = project_table_df[['Claim #', 'Job #', 'Branch', \n",
    "                                                  'Claim Status', 'Rep Claim Collected', \n",
    "                                                  'FTA Scope Completed', 'FTA Scope Rejected']]\n",
    "\n",
    "# information to be combined with the rep data from 'project_info_df'\n",
    "fta_scope_info_analysis_df = project_info_df[['Claim #', 'Job #', \n",
    "                                              'City', 'Building Department','Multi-rejected',\n",
    "                                              'Scope Rejections']]\n",
    "\n",
    "# information to be combined with the rep data from 'workflow_table_df'\n",
    "fta_scope_workflow_analysis_df = workflow_table_df[['Claim #', 'FTA Completing Scope']]\n",
    "\n",
    "\n",
    "# merging all of the dfs together to prepare rep claim analysis\n",
    "fta_scope_analysis_df = fta_scope_project_analysis_df.merge(\n",
    "    fta_scope_info_analysis_df, on=[\"Claim #\", \"Job #\"]).merge(\n",
    "    fta_scope_workflow_analysis_df, on=['Claim #'])\n",
    "\n",
    "# organizing the df\n",
    "fta_scope_analysis_df = fta_scope_analysis_df[['Claim #','Job #','Branch',\n",
    "                                               'Building Department','City','Rep Claim Collected',\n",
    "                                               'FTA Scope Completed', 'FTA Scope Rejected','FTA Completing Scope',\n",
    "                                               'Scope Rejections', 'Multi-rejected','Claim Status']]\n",
    "\n",
    "\n",
    "fta_scope_analysis_df = fta_scope_analysis_df.loc[fta_scope_analysis_df['FTA Scope Completed'].notnull()==True,:]\n",
    "\n",
    "\n",
    "fta_scope_analysis_df[\"Multi-rejected\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Building Department</th>\n",
       "      <th>City</th>\n",
       "      <th>Rep Claim Collected</th>\n",
       "      <th>FTA Scope Completed</th>\n",
       "      <th>FTA Scope Rejected</th>\n",
       "      <th>FTA Completing Scope</th>\n",
       "      <th>Scope Rejections</th>\n",
       "      <th>Multi-rejected</th>\n",
       "      <th>Claim Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00140067991A028</td>\n",
       "      <td>1938689</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denver</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>040357502</td>\n",
       "      <td>1938476</td>\n",
       "      <td>FCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fort collins</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001691605</td>\n",
       "      <td>1938472</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Westminster, City of (DEN)</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>020487835-7</td>\n",
       "      <td>1938470</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23255128-002</td>\n",
       "      <td>1938447</td>\n",
       "      <td>OMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Claim #    Job # Branch         Building Department          City  \\\n",
       "0  00140067991A028  1938689    DEN                         NaN        Denver   \n",
       "1        040357502  1938476    FCO                         NaN  fort collins   \n",
       "2      01001691605  1938472    DEN  Westminster, City of (DEN)   Westminster   \n",
       "3      020487835-7  1938470    DEN                         NaN   Westminster   \n",
       "4     23255128-002  1938447    OMA                         NaN         Omaha   \n",
       "\n",
       "  Rep Claim Collected FTA Scope Completed FTA Scope Rejected  \\\n",
       "0          2019-07-18          2019-07-20         2019-07-23   \n",
       "1          2019-07-15          2019-07-22                NaT   \n",
       "2          2019-07-15          2019-07-17                NaT   \n",
       "3          2019-07-15          2019-07-16                NaT   \n",
       "4          2019-07-16          2019-07-17         2019-07-23   \n",
       "\n",
       "   FTA Completing Scope  Scope Rejections Multi-rejected Claim Status  \n",
       "0                   5.0               1.0          False          NaN  \n",
       "1                   7.0               NaN            NaN          NaN  \n",
       "2                   2.0               NaN            NaN          NaN  \n",
       "3                   1.0               NaN            NaN          NaN  \n",
       "4                   7.0               1.0          False          NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fta_scope_analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Estimate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Estimate: 1969\n",
      "Quantile: 2.0\n",
      "Cleaned Records: 1793\n",
      "Outlier Records: 176\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'rep claim days'\n",
    "bc_quantile = workflow_table_df['BC Completing Estimate'].quantile(.90)\n",
    "num_bc_estimates = workflow_table_df['BC Completing Estimate'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_estimate_df = workflow_table_df.loc[(workflow_table_df['BC Completing Estimate'] >= 0) & (\n",
    "    workflow_table_df['BC Completing Estimate'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc estimate outlier df\n",
    "outlier_bc_estimate_df = workflow_table_df.loc[(workflow_table_df['BC Completing Estimate'] < 0) | (\n",
    "    workflow_table_df['BC Completing Estimate'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Estimate: {workflow_table_df['BC Completing Estimate'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")\n",
    "print(f\"Cleaned Records: {len(bc_estimate_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_estimate_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3.0     116\n",
       " 4.0      21\n",
       " 5.0      11\n",
       " 6.0       7\n",
       " 10.0      3\n",
       " 7.0       3\n",
       " 8.0       3\n",
       "-1.0       2\n",
       " 12.0      1\n",
       "-4.0       1\n",
       " 17.0      1\n",
       " 14.0      1\n",
       " 13.0      1\n",
       " 9.0       1\n",
       "-7.0       1\n",
       " 23.0      1\n",
       "-2.0       1\n",
       "-3.0       1\n",
       "Name: BC Completing Estimate, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_estimate_df['BC Completing Estimate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OB Scope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with OB Scope: 1865\n",
      "Quantile: 6.0\n",
      "Cleaned Records: 1711\n",
      "Outlier Records: 154\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ob scoped days'\n",
    "ob_quantile = workflow_table_df['OB Completing Scope'].quantile(.90)\n",
    "num_ob_scopes = workflow_table_df['OB Completing Scope'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ob_scope_df = workflow_table_df.loc[(workflow_table_df['OB Completing Scope'] >= 0) & (\n",
    "    workflow_table_df['OB Completing Scope'] <= ob_quantile), :]\n",
    "\n",
    "# creating a ob scoped outlier df\n",
    "outlier_ob_scope_df = workflow_table_df.loc[(workflow_table_df['OB Completing Scope'] < 0) | (\n",
    "    workflow_table_df['OB Completing Scope'] > ob_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with OB Scope: {workflow_table_df['OB Completing Scope'].count()}\")\n",
    "print(f\"Quantile: {ob_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ob_scope_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ob_scope_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 7.0     59\n",
       " 8.0     22\n",
       " 10.0    13\n",
       " 9.0     11\n",
       "-1.0     11\n",
       " 11.0    11\n",
       " 12.0     8\n",
       " 13.0     4\n",
       "-4.0      3\n",
       "-2.0      2\n",
       " 16.0     1\n",
       " 25.0     1\n",
       " 17.0     1\n",
       " 15.0     1\n",
       "-34.0     1\n",
       "-7.0      1\n",
       " 87.0     1\n",
       " 14.0     1\n",
       "-5.0      1\n",
       " 49.0     1\n",
       "Name: OB Completing Scope, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ob_scope_df['OB Completing Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# will want to see what is causing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outlier_ob_scope_df.to_csv(\"data/outliers/ob_scope_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sup Submittal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Sup Submit: 1191\n",
      "Quantile: 22.0\n",
      "Cleaned Records: 1078\n",
      "Outlier Records: 113\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'sup submitted days'\n",
    "sup_quantile = workflow_table_df['Sup Submitting Job'].quantile(.90)\n",
    "num_sup_submits = workflow_table_df['Sup Submitting Job'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "sup_submit_df = workflow_table_df.loc[(workflow_table_df['Sup Submitting Job'] >= 0) & (\n",
    "    workflow_table_df['Sup Submitting Job'] <= sup_quantile), :]\n",
    "\n",
    "# creating a sup submitted outlier df\n",
    "outlier_sup_submit_df = workflow_table_df.loc[(workflow_table_df['Sup Submitting Job'] < 0) | (\n",
    "    workflow_table_df['Sup Submitting Job'] > sup_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Sup Submit: {workflow_table_df['Sup Submitting Job'].count()}\")\n",
    "print(f\"Quantile: {sup_quantile}\")\n",
    "print(f\"Cleaned Records: {len(sup_submit_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_sup_submit_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 23.0    13\n",
       " 27.0    10\n",
       " 33.0     8\n",
       " 34.0     7\n",
       " 24.0     6\n",
       " 38.0     5\n",
       " 37.0     4\n",
       " 26.0     4\n",
       " 28.0     3\n",
       " 29.0     3\n",
       " 56.0     3\n",
       " 40.0     3\n",
       " 39.0     3\n",
       " 35.0     3\n",
       " 31.0     3\n",
       " 43.0     3\n",
       " 25.0     3\n",
       " 30.0     2\n",
       "-2.0      2\n",
       " 41.0     2\n",
       "-4.0      2\n",
       " 42.0     2\n",
       " 36.0     2\n",
       " 51.0     2\n",
       " 45.0     2\n",
       " 46.0     2\n",
       " 44.0     1\n",
       " 32.0     1\n",
       " 50.0     1\n",
       " 61.0     1\n",
       " 49.0     1\n",
       " 62.0     1\n",
       " 48.0     1\n",
       "-5.0      1\n",
       " 60.0     1\n",
       "-10.0     1\n",
       " 66.0     1\n",
       "Name: Sup Submitting Job, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_sup_submit_df['Sup Submitting Job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Approval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Approval: 1118\n",
      "Quantile: 8.300000000000068\n",
      "Cleaned Records: 1003\n",
      "Outlier Records: 115\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc approved days'\n",
    "bc_quantile = workflow_table_df['BC Approving Job'].quantile(.90)\n",
    "num_bc_approvals = workflow_table_df['BC Approving Job'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_approval_df = workflow_table_df.loc[(workflow_table_df['BC Approving Job'] >= 0) & (\n",
    "    workflow_table_df['BC Approving Job'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc approved outlier df\n",
    "outlier_bc_approval_df = workflow_table_df.loc[(workflow_table_df['BC Approving Job'] < 0) | (\n",
    "    workflow_table_df['BC Approving Job'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Approval: {workflow_table_df['BC Approving Job'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")\n",
    "print(f\"Cleaned Records: {len(bc_approval_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_approval_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 13.0    15\n",
       " 9.0     14\n",
       " 12.0    13\n",
       " 11.0    12\n",
       " 20.0     8\n",
       " 19.0     7\n",
       " 14.0     5\n",
       " 26.0     5\n",
       " 10.0     4\n",
       " 17.0     4\n",
       " 21.0     4\n",
       " 25.0     4\n",
       " 18.0     3\n",
       " 16.0     3\n",
       " 23.0     2\n",
       " 15.0     2\n",
       " 27.0     1\n",
       " 41.0     1\n",
       " 35.0     1\n",
       "-11.0     1\n",
       " 39.0     1\n",
       " 29.0     1\n",
       "-13.0     1\n",
       " 32.0     1\n",
       "-4.0      1\n",
       " 46.0     1\n",
       "Name: BC Approving Job, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_approval_df['BC Approving Job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OB Create Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with OB Order: 1085\n",
      "Quantile: 5.0\n",
      "Cleaned Records: 990\n",
      "Outlier Records: 95\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ob created days'\n",
    "ob_quantile = workflow_table_df['OB Building Order'].quantile(.90)\n",
    "num_ob_orders = workflow_table_df['OB Building Order'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ob_order_df = workflow_table_df.loc[(workflow_table_df['OB Building Order'] >= 0) & (\n",
    "    workflow_table_df['OB Building Order'] <= ob_quantile), :]\n",
    "\n",
    "# creating a ob created outlier df\n",
    "outlier_ob_order_df = workflow_table_df.loc[(workflow_table_df['OB Building Order'] < 0) | (\n",
    "    workflow_table_df['OB Building Order'] > ob_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with OB Order: {workflow_table_df['OB Building Order'].count()}\")\n",
    "print(f\"Quantile: {ob_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ob_order_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ob_order_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 7.0     15\n",
       " 6.0     14\n",
       " 11.0    12\n",
       " 8.0      9\n",
       " 10.0     9\n",
       " 9.0      9\n",
       " 12.0     7\n",
       " 13.0     4\n",
       " 15.0     4\n",
       " 20.0     4\n",
       " 16.0     2\n",
       "-9.0      1\n",
       " 53.0     1\n",
       " 27.0     1\n",
       " 28.0     1\n",
       " 24.0     1\n",
       " 40.0     1\n",
       "Name: OB Building Order, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ob_order_df['OB Building Order'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GM Process Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with GM Processed Order: 884\n",
      "Quantile: 20.0\n",
      "Cleaned Records: 796\n",
      "Outlier Records: 88\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'gm processed days'\n",
    "gm_quantile = workflow_table_df['GM Processing Order'].quantile(.90)\n",
    "num_gm_orders = workflow_table_df['GM Processing Order'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "gm_order_df = workflow_table_df.loc[(workflow_table_df['GM Processing Order'] >= 0) & (\n",
    "    workflow_table_df['GM Processing Order'] <= gm_quantile), :]\n",
    "\n",
    "# creating a gm processed outlier df\n",
    "outlier_gm_order_df = workflow_table_df.loc[(workflow_table_df['GM Processing Order'] < 0) | (\n",
    "    workflow_table_df['GM Processing Order'] > gm_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with GM Processed Order: {workflow_table_df['GM Processing Order'].count()}\")\n",
    "print(f\"Quantile: {gm_quantile}\")\n",
    "print(f\"Cleaned Records: {len(gm_order_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_gm_order_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 21.0    12\n",
       " 22.0     9\n",
       " 29.0     8\n",
       " 27.0     7\n",
       " 28.0     7\n",
       " 24.0     7\n",
       " 30.0     5\n",
       " 23.0     4\n",
       " 38.0     3\n",
       " 34.0     3\n",
       " 36.0     3\n",
       " 25.0     2\n",
       " 41.0     2\n",
       " 26.0     2\n",
       " 42.0     2\n",
       " 47.0     1\n",
       " 60.0     1\n",
       "-7.0      1\n",
       " 40.0     1\n",
       " 35.0     1\n",
       " 55.0     1\n",
       " 46.0     1\n",
       " 63.0     1\n",
       " 54.0     1\n",
       " 37.0     1\n",
       " 43.0     1\n",
       " 32.0     1\n",
       "Name: GM Processing Order, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_gm_order_df['GM Processing Order'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# will want to determine what is causing the outliers\n",
    "outlier_gm_order_df.to_csv(\"data_copy/outliers/gm_order_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PA Process OA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with PA OA Processed: 827\n",
      "Quantile: 3.0\n",
      "Cleaned Records: 756\n",
      "Outlier Records: 71\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'pa oa processeddays'\n",
    "pa_quantile = workflow_table_df['PA Processing OA'].quantile(.90)\n",
    "num_pa_oa_processed = workflow_table_df['PA Processing OA'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "pa_processed_oa_df = workflow_table_df.loc[(workflow_table_df['PA Processing OA'] >= 0) & (\n",
    "    workflow_table_df['PA Processing OA'] <= pa_quantile), :]\n",
    "\n",
    "# creating a pa oa processedoutlier df\n",
    "outlier_pa_processed_oa_df = workflow_table_df.loc[(workflow_table_df['PA Processing OA'] < 0) | (\n",
    "    workflow_table_df['PA Processing OA'] > pa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with PA OA Processed: {workflow_table_df['PA Processing OA'].count()}\")\n",
    "print(f\"Quantile: {pa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(pa_processed_oa_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_pa_processed_oa_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0     24\n",
       " 5.0     20\n",
       " 6.0      7\n",
       " 10.0     4\n",
       " 7.0      2\n",
       " 11.0     2\n",
       " 8.0      2\n",
       " 30.0     1\n",
       " 17.0     1\n",
       " 12.0     1\n",
       "-10.0     1\n",
       " 20.0     1\n",
       " 14.0     1\n",
       " 15.0     1\n",
       "-1.0      1\n",
       " 42.0     1\n",
       " 18.0     1\n",
       "Name: PA Processing OA, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_pa_processed_oa_df['PA Processing OA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PA Invoicing OA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with PA OA Invoiced: 714\n",
      "Quantile: 8.0\n",
      "Cleaned Records: 668\n",
      "Outlier Records: 46\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'pa oa invoiceddays'\n",
    "pa_quantile = workflow_table_df['PA Invoicing OA'].quantile(.90)\n",
    "num_pa_oa_invoiced = workflow_table_df['PA Invoicing OA'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "pa_invoiced_oa_df = workflow_table_df.loc[(workflow_table_df['PA Invoicing OA'] >= 0) & (\n",
    "    workflow_table_df['PA Invoicing OA'] <= pa_quantile), :]\n",
    "\n",
    "# creating a pa oa invoicedoutlier df\n",
    "outlier_pa_invoiced_oa_df = workflow_table_df.loc[(workflow_table_df['PA Invoicing OA'] < 0) | (\n",
    "    workflow_table_df['PA Invoicing OA'] > pa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with PA OA Invoiced: {workflow_table_df['PA Invoicing OA'].count()}\")\n",
    "print(f\"Quantile: {pa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(pa_invoiced_oa_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_pa_invoiced_oa_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0    14\n",
       "9.0     10\n",
       "10.0     4\n",
       "15.0     3\n",
       "12.0     3\n",
       "19.0     3\n",
       "13.0     2\n",
       "33.0     1\n",
       "21.0     1\n",
       "20.0     1\n",
       "18.0     1\n",
       "14.0     1\n",
       "16.0     1\n",
       "28.0     1\n",
       "Name: PA Invoicing OA, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_pa_invoiced_oa_df['PA Invoicing OA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_pa_invoiced_oa_df.to_csv(\"data_copy/outliers/pa_invoiced_oa_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GM Approving for Inspection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with GM Approved for Inspection: 645\n",
      "Quantile: 3.0\n",
      "Cleaned Records: 587\n",
      "Outlier Records: 58\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'gm approved for inspection days'\n",
    "gm_quantile = workflow_table_df['GM Approving for Inspection'].quantile(.90)\n",
    "num_gm_approved_inspection = workflow_table_df['GM Approving for Inspection'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "gm_approved_inspection_df = workflow_table_df.loc[(workflow_table_df['GM Approving for Inspection'] >= 0) & (\n",
    "    workflow_table_df['GM Approving for Inspection'] <= gm_quantile), :]\n",
    "\n",
    "# creating a gm approved for inspection outlier df\n",
    "outlier_gm_approved_inspection_df = workflow_table_df.loc[(workflow_table_df['GM Approving for Inspection'] < 0) | (\n",
    "    workflow_table_df['GM Approving for Inspection'] > gm_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with GM Approved for Inspection: {workflow_table_df['GM Approving for Inspection'].count()}\")\n",
    "print(f\"Quantile: {gm_quantile}\")\n",
    "print(f\"Cleaned Records: {len(gm_approved_inspection_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_gm_approved_inspection_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0     26\n",
       "5.0     17\n",
       "6.0     13\n",
       "30.0     1\n",
       "8.0      1\n",
       "Name: GM Approving for Inspection, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_gm_approved_inspection_df['GM Approving for Inspection'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_gm_approved_inspection_df.to_csv(\"data_copy/outliers/gm_approved_inspection_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RA Requesting Inspection Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with RA Requested Inspection: 280\n",
      "Quantile: 18.0\n",
      "Cleaned Records: 254\n",
      "Outlier Records: 26\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ra requesting inspection days'\n",
    "ra_quantile = workflow_table_df['RA Requesting Inspection'].quantile(.90)\n",
    "num_ra_requested = workflow_table_df['RA Requesting Inspection'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ra_requested_inspection_df = workflow_table_df.loc[(workflow_table_df['RA Requesting Inspection'] >= 0) & (\n",
    "    workflow_table_df['RA Requesting Inspection'] <= ra_quantile), :]\n",
    "\n",
    "# creating a ra requesting inspection outlier df\n",
    "outlier_ra_requested_inspection_df = workflow_table_df.loc[(workflow_table_df['RA Requesting Inspection'] < 0) | (\n",
    "    workflow_table_df['RA Requesting Inspection'] > ra_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with RA Requested Inspection: {workflow_table_df['RA Requesting Inspection'].count()}\")\n",
    "print(f\"Quantile: {ra_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ra_requested_inspection_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ra_requested_inspection_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0    4\n",
       "20.0    3\n",
       "25.0    3\n",
       "27.0    2\n",
       "22.0    2\n",
       "26.0    1\n",
       "21.0    1\n",
       "42.0    1\n",
       "36.0    1\n",
       "45.0    1\n",
       "67.0    1\n",
       "24.0    1\n",
       "28.0    1\n",
       "61.0    1\n",
       "47.0    1\n",
       "31.0    1\n",
       "41.0    1\n",
       "Name: RA Requesting Inspection, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ra_requested_inspection_df['RA Requesting Inspection'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rep Collecting COC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Rep COC Collected: 615\n",
      "Quantile: 15.0\n",
      "Cleaned Records: 556\n",
      "Outlier Records: 59\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'rep collect coc days'\n",
    "rep_quantile = workflow_table_df['Rep Collecting COC'].quantile(.90)\n",
    "num_rep_collected = workflow_table_df['Rep Collecting COC'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "rep_collected_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting COC'] >= 0) & (\n",
    "    workflow_table_df['Rep Collecting COC'] <= rep_quantile), :]\n",
    "\n",
    "# creating a rep collect coc outlier df\n",
    "outlier_rep_collected_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting COC'] < 0) | (\n",
    "    workflow_table_df['Rep Collecting COC'] > rep_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Rep COC Collected: {workflow_table_df['Rep Collecting COC'].count()}\")\n",
    "print(f\"Quantile: {rep_quantile}\")\n",
    "print(f\"Cleaned Records: {len(rep_collected_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_rep_collected_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0    10\n",
       "20.0     6\n",
       "19.0     4\n",
       "23.0     4\n",
       "17.0     4\n",
       "24.0     3\n",
       "22.0     3\n",
       "35.0     2\n",
       "21.0     2\n",
       "26.0     2\n",
       "33.0     2\n",
       "18.0     2\n",
       "37.0     2\n",
       "28.0     2\n",
       "29.0     1\n",
       "47.0     1\n",
       "43.0     1\n",
       "25.0     1\n",
       "62.0     1\n",
       "46.0     1\n",
       "34.0     1\n",
       "50.0     1\n",
       "32.0     1\n",
       "49.0     1\n",
       "30.0     1\n",
       "Name: Rep Collecting COC, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_rep_collected_df['Rep Collecting COC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_rep_collected_df.to_csv(\"data_copy/outliers/rep_collected_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SA Uploading Docs Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with SA Docs Uploaded: 522\n",
      "Quantile: 16.0\n",
      "Cleaned Records: 473\n",
      "Outlier Records: 49\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'sa uploaded days'\n",
    "sa_quantile = workflow_table_df['SA Uploading Docs'].quantile(.90)\n",
    "num_sa_uploaded = workflow_table_df['SA Uploading Docs'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "sa_uploaded_df = workflow_table_df.loc[(workflow_table_df['SA Uploading Docs'] >= 0) & (\n",
    "    workflow_table_df['SA Uploading Docs'] <= sa_quantile), :]\n",
    "\n",
    "# creating a sa uploaded outlier df\n",
    "outlier_sa_uploaded_df = workflow_table_df.loc[(workflow_table_df['SA Uploading Docs'] < 0) | (\n",
    "    workflow_table_df['SA Uploading Docs'] > sa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with SA Docs Uploaded: {workflow_table_df['SA Uploading Docs'].count()}\")\n",
    "print(f\"Quantile: {sa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(sa_uploaded_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_sa_uploaded_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0    8\n",
       "26.0    5\n",
       "19.0    4\n",
       "25.0    4\n",
       "32.0    3\n",
       "24.0    3\n",
       "18.0    3\n",
       "27.0    3\n",
       "28.0    2\n",
       "37.0    2\n",
       "23.0    2\n",
       "20.0    2\n",
       "17.0    2\n",
       "22.0    1\n",
       "54.0    1\n",
       "33.0    1\n",
       "29.0    1\n",
       "44.0    1\n",
       "71.0    1\n",
       "Name: SA Uploading Docs, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_sa_uploaded_df['SA Uploading Docs'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Invoicing Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Project Invoiced: 464\n",
      "Quantile: 9.0\n",
      "Cleaned Records: 422\n",
      "Outlier Records: 42\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc invoiced days'\n",
    "bc_quantile = workflow_table_df['BC Invoicing Project'].quantile(.90)\n",
    "num_bc_invoiced = workflow_table_df['BC Invoicing Project'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_invoiced_df = workflow_table_df.loc[(workflow_table_df['BC Invoicing Project'] >= 0) & (\n",
    "    workflow_table_df['BC Invoicing Project'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc invoiced outlier df\n",
    "outlier_bc_invoiced_df = workflow_table_df.loc[(workflow_table_df['BC Invoicing Project'] < 0) | (\n",
    "    workflow_table_df['BC Invoicing Project'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Project Invoiced: {workflow_table_df['BC Invoicing Project'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")      \n",
    "print(f\"Cleaned Records: {len(bc_invoiced_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_invoiced_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0    7\n",
       "15.0    6\n",
       "10.0    6\n",
       "12.0    5\n",
       "11.0    5\n",
       "16.0    3\n",
       "17.0    3\n",
       "13.0    3\n",
       "18.0    2\n",
       "21.0    1\n",
       "20.0    1\n",
       "Name: BC Invoicing Project, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_invoiced_df['BC Invoicing Project'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Closed Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Project Closed: 237\n",
      "Quantile: 41.0\n",
      "Cleaned Records: 216\n",
      "Outlier Records: 21\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc closed days'\n",
    "bc_quantile = workflow_table_df['BC Closed Project'].quantile(.90)\n",
    "num_bc_closed = workflow_table_df['BC Closed Project'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_closed_df = workflow_table_df.loc[(workflow_table_df['BC Closed Project'] >= 0) & (\n",
    "    workflow_table_df['BC Closed Project'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc closed outlier df\n",
    "outlier_bc_closed_df = workflow_table_df.loc[(workflow_table_df['BC Closed Project'] < 0) | (\n",
    "    workflow_table_df['BC Closed Project'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Project Closed: {workflow_table_df['BC Closed Project'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")      \n",
    "print(f\"Cleaned Records: {len(bc_closed_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_closed_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.0    2\n",
       "49.0    2\n",
       "51.0    2\n",
       "43.0    2\n",
       "47.0    2\n",
       "48.0    1\n",
       "69.0    1\n",
       "78.0    1\n",
       "67.0    1\n",
       "63.0    1\n",
       "70.0    1\n",
       "77.0    1\n",
       "71.0    1\n",
       "68.0    1\n",
       "50.0    1\n",
       "42.0    1\n",
       "Name: BC Closed Project, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_closed_df['BC Closed Project'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.521px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "695.208px",
    "left": "830px",
    "right": "20px",
    "top": "120px",
    "width": "314.774px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
