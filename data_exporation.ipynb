{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Tables Created\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'data_prep' from 'P:\\\\Programming\\\\Local Apps\\\\Premier Projects\\\\workflow_project\\\\data_prep.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import data_prep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datestamp_table():\n",
    "\n",
    "    # imports the 'project table' data\n",
    "    project_table_data = \"./data/cleaned_data/project_table.csv\"\n",
    "    project_table_df = pd.read_csv(\n",
    "        project_table_data, dtype={\n",
    "            'Claim #': str,\n",
    "            'Job #': str,\n",
    "            'Branch':str,\n",
    "            'Claim Status':str},\n",
    "        parse_dates=[\n",
    "            'Rep Agreement Signed', 'Rep Claim Collected','FTA Scope Completed',\n",
    "            'FTA Scope Rejected', 'BC Estimate Completed','OB Scope Completed',\n",
    "            'Sup Job Submitted', 'BC Approved for Production', 'OB Order Built',\n",
    "            'GM Order Processed', 'PA Permit Applied', 'PA Permit Processed',\n",
    "            'PA OA Processed', 'PA OA Invoiced', 'PA Notify of Delivery',\n",
    "            'PA Notify of Start', 'Delivery Date', 'Roof Start',\n",
    "            'Roof End', 'GM Approved for Inspection', 'GM Change Order Date',\n",
    "            'GM Labor Adjustment Date', 'RA Inspection Requested', 'RA Inspection Processed', \n",
    "            'Rep COC Collected', 'SA Job Docs Uploaded', 'BC Project Invoiced','BC Project Closed'])\n",
    "    return project_table_df\n",
    "\n",
    "# datestamp_table()\n",
    "\n",
    "def info_table():\n",
    "\n",
    "    # imports the 'project information' data\n",
    "    project_info_data = \"./data/cleaned_data/project_info_table.csv\"\n",
    "\n",
    "    project_info_df = pd.read_csv(project_info_data, dtype={\n",
    "        'Claim #':str, 'Job #':str, 'Branch':str, 'City':str, 'Building Department':str,\n",
    "        'Permit Req?':str, 'Supplier Name':str, 'Crew':str, 'Insurance Company':str,\n",
    "        'Multi-rejected':str, 'Scope Rejections':str, 'Change Orders':str,'Labor Adjustments':str})\n",
    "    \n",
    "    # due to manual 'city' field, city is incorrectly spelled or off on capitalization\n",
    "    project_info_df['City'] = project_info_df['City'].str.upper()\n",
    "\n",
    "    return project_info_df\n",
    "\n",
    "# info_table()\n",
    "\n",
    "def workflow_table():\n",
    "\n",
    "    # imports 'workflow table' data\n",
    "    workflow_table_data = \"./data/cleaned_data/workflow_table.csv\"\n",
    "    workflow_table_df = pd.read_csv(workflow_table_data)\n",
    "\n",
    "    return workflow_table_df\n",
    "\n",
    "# workflow_table()\n",
    "\n",
    "def eagleview_table():\n",
    "    \n",
    "    # imports the 'eagleview table' data\n",
    "    eagleview_table_data = \"./data/trackvia_data/eagleview_analysis.csv\"\n",
    "    eagleview_table_df = pd.read_csv(eagleview_table_data)\n",
    "    \n",
    "    # converting the squares measurement to roofing SQs\n",
    "    eagleview_table_df['Square Feet'] = eagleview_table_df['Square Feet'] / 100\n",
    "    \n",
    "    return eagleview_table_df\n",
    "\n",
    "# eagleview_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interquartile Range for Each Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2704\n",
      "2873\n"
     ]
    }
   ],
   "source": [
    "workflow_table_df = workflow_table()\n",
    "Q1 = workflow_table_df['Rep Collecting Claim'].quantile(0.25)\n",
    "Q3 = workflow_table_df['Rep Collecting Claim'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "fence_low = Q1 - 1.5 * IQR\n",
    "fence_high = Q3 + 1.5 * IQR\n",
    "\n",
    "df_out = workflow_table_df.loc[ (workflow_table_df['Rep Collecting Claim'] > fence_low ) & (workflow_table_df['Rep Collecting Claim'] <  fence_high) ]\n",
    "\n",
    "print(len(df_out))\n",
    "print(len(workflow_table_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-65-2c007c586f92>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-65-2c007c586f92>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    Q1 = df_in[col_name].quantile(0.25)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "workflow_table_df = workflow_table()\n",
    "\n",
    "def remove_outlier_data(df_in, col_name):\n",
    "    Q1 = df_in[col_name].quantile(0.25)\n",
    "    Q3 = df_in[col_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    fence_low = Q1 - 1.5 * IQR\n",
    "    fence_high = Q3 - 1.5 * IQR\n",
    " \n",
    "    df_out = df_in.loc[ (df_in[col_name] > fence_low ) & (df_in[col_name] <  fence_high) ]\n",
    "    \n",
    "    return df_out\n",
    "\n",
    "remove_outlier_data(workflow_table_df, 'Rep Collecting Claim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating an empty dataframe to hold outliers\n",
    "rep_claim_outliers = []\n",
    "\n",
    "def rep_claim_data():\n",
    "    \n",
    "    \n",
    "    threshold = 3\n",
    "    average = np.mean(workflow_table_df['Rep Collecting Claim'])\n",
    "    standard_deviation = np.std(workflow_table_df['Rep Collecting Claim'])\n",
    "    \n",
    "    # iterates over rows in a df\n",
    "    for index, row in workflow_table_df.iterrows():\n",
    "        outlier_dict = {}\n",
    "        \n",
    "        z_score = (row['Rep Collecting Claim'] - average) / standard_deviation\n",
    "        \n",
    "        if np.abs(z_score) > threshold:\n",
    "            \n",
    "            rep_claim_outliers.append(outlier_dict)\n",
    "            \n",
    "            \n",
    "    outlier_df = pd.DataFrame(outlier_dict)\n",
    "        \n",
    "    return outlier_df\n",
    "\n",
    "rep_claim_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Rep Claim: 2814\n",
      "Quantile: 15.0\n",
      "Cleaned Records: 2542\n",
      "Outlier Records: 272\n"
     ]
    }
   ],
   "source": [
    "workflow_table_df = workflow_table()\n",
    "\n",
    "# created a variable to be able to allow a 10% error in 'rep claim days'\n",
    "rep_quantile = workflow_table_df['Rep Collecting Claim'].quantile(.90)\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "rep_claim_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting Claim'] >= 0) & (\n",
    "    workflow_table_df['Rep Collecting Claim'] <= rep_quantile), :]\n",
    "\n",
    "# rep_claim_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting Claim'] >= 0), :]\n",
    "\n",
    "# creating a rep claim outlier df\n",
    "outlier_rep_claim_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting Claim'] < 0) | (\n",
    "    workflow_table_df['Rep Collecting Claim'] > rep_quantile), :]\n",
    "\n",
    "# outlier_rep_claim_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting Claim'] < 0), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Rep Claim: {workflow_table_df['Rep Collecting Claim'].count()}\")\n",
    "print(f\"Quantile: {rep_quantile}\")\n",
    "print(f\"Cleaned Records: {len(rep_claim_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_rep_claim_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rep Collecting Claim</th>\n",
       "      <th>FTA Completing Scope</th>\n",
       "      <th>BC Completing Estimate</th>\n",
       "      <th>OB Completing Scope</th>\n",
       "      <th>Sup Submitting Job</th>\n",
       "      <th>BC Approving Job</th>\n",
       "      <th>OB Building Order</th>\n",
       "      <th>GM Processing Order</th>\n",
       "      <th>PA Processing OA</th>\n",
       "      <th>PA Invoicing OA</th>\n",
       "      <th>GM Approving for Inspection</th>\n",
       "      <th>RA Requesting Inspection</th>\n",
       "      <th>Rep Collecting COC</th>\n",
       "      <th>SA Uploading Docs</th>\n",
       "      <th>BC Invoicing Project</th>\n",
       "      <th>BC Closed Project</th>\n",
       "      <th>Days in Pipeline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2542.000000</td>\n",
       "      <td>2191.000000</td>\n",
       "      <td>2160.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>1341.000000</td>\n",
       "      <td>1266.000000</td>\n",
       "      <td>1210.000000</td>\n",
       "      <td>958.000000</td>\n",
       "      <td>903.000000</td>\n",
       "      <td>829.000000</td>\n",
       "      <td>752.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>690.000000</td>\n",
       "      <td>609.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>306.000000</td>\n",
       "      <td>2542.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.913454</td>\n",
       "      <td>6.696942</td>\n",
       "      <td>0.816204</td>\n",
       "      <td>2.138693</td>\n",
       "      <td>10.883669</td>\n",
       "      <td>3.561611</td>\n",
       "      <td>1.622314</td>\n",
       "      <td>8.718163</td>\n",
       "      <td>1.655592</td>\n",
       "      <td>4.483715</td>\n",
       "      <td>1.513298</td>\n",
       "      <td>6.339394</td>\n",
       "      <td>6.168116</td>\n",
       "      <td>8.561576</td>\n",
       "      <td>3.828154</td>\n",
       "      <td>18.797386</td>\n",
       "      <td>33.759638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.278156</td>\n",
       "      <td>6.357133</td>\n",
       "      <td>1.365565</td>\n",
       "      <td>3.476107</td>\n",
       "      <td>10.817063</td>\n",
       "      <td>5.672602</td>\n",
       "      <td>3.646542</td>\n",
       "      <td>10.100638</td>\n",
       "      <td>3.091704</td>\n",
       "      <td>3.920870</td>\n",
       "      <td>2.199706</td>\n",
       "      <td>9.881976</td>\n",
       "      <td>8.197357</td>\n",
       "      <td>7.684565</td>\n",
       "      <td>4.225305</td>\n",
       "      <td>18.917200</td>\n",
       "      <td>30.090433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-83.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-34.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>-9.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>27.750000</td>\n",
       "      <td>54.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rep Collecting Claim  FTA Completing Scope  BC Completing Estimate  \\\n",
       "count           2542.000000           2191.000000             2160.000000   \n",
       "mean               3.913454              6.696942                0.816204   \n",
       "std                4.278156              6.357133                1.365565   \n",
       "min                0.000000            -83.000000               -7.000000   \n",
       "25%                0.000000              2.000000                0.000000   \n",
       "50%                2.000000              5.000000                0.000000   \n",
       "75%                7.000000              9.000000                1.000000   \n",
       "max               15.000000             43.000000               23.000000   \n",
       "\n",
       "       OB Completing Scope  Sup Submitting Job  BC Approving Job  \\\n",
       "count          1990.000000         1341.000000       1266.000000   \n",
       "mean              2.138693           10.883669          3.561611   \n",
       "std               3.476107           10.817063          5.672602   \n",
       "min             -34.000000          -23.000000        -13.000000   \n",
       "25%               0.000000            4.000000          1.000000   \n",
       "50%               1.000000            8.000000          1.000000   \n",
       "75%               3.000000           15.000000          4.000000   \n",
       "max              87.000000           90.000000         46.000000   \n",
       "\n",
       "       OB Building Order  GM Processing Order  PA Processing OA  \\\n",
       "count        1210.000000           958.000000        903.000000   \n",
       "mean            1.622314             8.718163          1.655592   \n",
       "std             3.646542            10.100638          3.091704   \n",
       "min            -9.000000             0.000000        -10.000000   \n",
       "25%             0.000000             2.000000          0.000000   \n",
       "50%             0.000000             6.000000          1.000000   \n",
       "75%             2.000000            13.000000          2.000000   \n",
       "max            53.000000           113.000000         42.000000   \n",
       "\n",
       "       PA Invoicing OA  GM Approving for Inspection  RA Requesting Inspection  \\\n",
       "count       829.000000                   752.000000                330.000000   \n",
       "mean          4.483715                     1.513298                  6.339394   \n",
       "std           3.920870                     2.199706                  9.881976   \n",
       "min           0.000000                     0.000000                 -8.000000   \n",
       "25%           2.000000                     0.000000                  1.000000   \n",
       "50%           4.000000                     1.000000                  3.000000   \n",
       "75%           6.000000                     3.000000                  7.000000   \n",
       "max          61.000000                    30.000000                 67.000000   \n",
       "\n",
       "       Rep Collecting COC  SA Uploading Docs  BC Invoicing Project  \\\n",
       "count          690.000000         609.000000            547.000000   \n",
       "mean             6.168116           8.561576              3.828154   \n",
       "std              8.197357           7.684565              4.225305   \n",
       "min              0.000000          -1.000000              0.000000   \n",
       "25%              1.000000           2.000000              1.000000   \n",
       "50%              4.000000           8.000000              2.000000   \n",
       "75%              8.000000          12.000000              6.000000   \n",
       "max             62.000000          71.000000             21.000000   \n",
       "\n",
       "       BC Closed Project  Days in Pipeline  \n",
       "count         306.000000       2542.000000  \n",
       "mean           18.797386         33.759638  \n",
       "std            18.917200         30.090433  \n",
       "min             0.000000        -38.000000  \n",
       "25%             6.000000         11.000000  \n",
       "50%            13.500000         23.000000  \n",
       "75%            27.750000         54.000000  \n",
       "max            97.000000        186.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_rep_claim_df['Rep Collecting Claim'].value_counts()\n",
    "rep_claim_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information to be combined with the rep data from 'project_table_df'\n",
    "rep_claim_project_analysis_df = project_table_df[['Claim #', 'Job #','Claim Status','Rep Agreement Signed',\n",
    "                                                  'Rep Claim Collected', 'FTA Scope Completed']]\n",
    "\n",
    "# information to be combined with the rep data from 'project_info_df'\n",
    "rep_claim_info_analysis_df = project_info_df[['Claim #', 'Job #', 'Branch', \n",
    "                                              'City', 'Building Department',]]\n",
    "\n",
    "# information to be combined with the rep data from 'workflow_table_df'\n",
    "rep_claim_workflow_analysis_df = workflow_table_df[['Claim #', 'Rep Collecting Claim']]\n",
    "\n",
    "\n",
    "# merging all of the dfs together to prepare rep claim analysis\n",
    "rep_claim_analysis_df = rep_claim_project_analysis_df.merge(\n",
    "    rep_claim_info_analysis_df, on=[\"Claim #\", \"Job #\"]).merge(\n",
    "    rep_claim_workflow_analysis_df, on=['Claim #'])\n",
    "\n",
    "# organizing the df\n",
    "rep_claim_analysis_df = rep_claim_analysis_df[['Claim #','Job #','Branch',\n",
    "                                               'Building Department','City',\n",
    "                                               'Rep Agreement Signed','Rep Claim Collected',\n",
    "                                               'Rep Collecting Claim','FTA Scope Completed','Claim Status']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n",
      "1009\n",
      "328\n",
      "673\n",
      "226\n"
     ]
    }
   ],
   "source": [
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'DEN', :]))\n",
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'FCO', :]))\n",
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'COS', :]))\n",
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'KCI', :]))\n",
    "print(len(rep_claim_analysis_df.loc[ rep_claim_analysis_df['Branch'] == 'OMA', :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Claims Collected by Reps': 378, 'Average Days to Collect': 7.52}\n",
      "{'Claims Collected by Reps': 1009, 'Average Days to Collect': 3.86}\n",
      "{'Claims Collected by Reps': 328, 'Average Days to Collect': 7.63}\n",
      "{'Claims Collected by Reps': 673, 'Average Days to Collect': 7.64}\n",
      "{'Claims Collected by Reps': 226, 'Average Days to Collect': 9.9}\n"
     ]
    }
   ],
   "source": [
    "# created a 'branches' list to iterate over\n",
    "branches = ['DEN', 'FCO', 'COS', 'KCI', 'OMA' ]\n",
    "\n",
    "den_workflow_dict = {}\n",
    "fco_workflow_dict = {}\n",
    "cos_workflow_dict = {}\n",
    "kci_workflow_dict = {}\n",
    "oma_workflow_dict = {}\n",
    "\n",
    "for branch in branches:\n",
    "    \n",
    "    # separating the df into branches according to the 'branches' list\n",
    "    branch_rep_claim_analysis = rep_claim_analysis_df.loc[rep_claim_analysis_df['Branch'] == branch, :]\n",
    "    \n",
    "    # determining how many claim #s have been collected, 'dead' or not\n",
    "    rep_claim_collected_count = branch_rep_claim_analysis['Rep Claim Collected'].count()\n",
    "    \n",
    "    # determining the average amount of days to collect claim, 'dead' or not\n",
    "    rep_claim_collected_avg_days = round(branch_rep_claim_analysis['Rep Collecting Claim'].mean(), 2)\n",
    "    \n",
    "    # determing the count of 'dead' jobs per branch; provide insight on jobs that were actually marked 'dead' \n",
    "    # at this stage in the workflow (never got FTA Scoped)\n",
    "    rep_claims_dead_analysis = branch_rep_claim_analysis.loc[(branch_rep_claim_analysis['Claim Status'] == 'Dead' ) & (branch_rep_claim_analysis['FTA Scope Completed'].isnull() == True), : ]\n",
    "    rep_claim_dead_count = rep_claims_dead_analysis['Claim Status'].count()\n",
    "    \n",
    "    # iterating over each city in the 'branch' to better understand project concentration\n",
    "    city_list = branch_rep_claim_analysis['City'].unique()\n",
    "    \n",
    "    for city in city_list:\n",
    "       \n",
    "        # separating the 'branches' df into a smaller 'city' df\n",
    "        city_rep_claim_analysis = branch_rep_claim_analysis.loc[ branch_rep_claim_analysis['City'] == city, :]\n",
    "        \n",
    "        # determining how many claim #s have been collected in each city\n",
    "        city_rep_claim_collected_count = city_rep_claim_analysis['Rep Claim Collected'].count()\n",
    "        \n",
    "        # determining the average amount of days to collect claim in each city\n",
    "        city_rep_claim_collected_avg_days = round(city_rep_claim_analysis['Rep Collecting Claim'].mean(), 2)\n",
    "        \n",
    "    if branch == 'DEN':\n",
    "        \n",
    "        # update the 'den' dictionary\n",
    "        den_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])\n",
    "    \n",
    "    elif branch == 'FCO':\n",
    "        \n",
    "        # update the 'fco' dictionary\n",
    "        fco_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])\n",
    "\n",
    "    elif branch == 'COS':\n",
    "        \n",
    "        # update the 'cos' dictionary\n",
    "        cos_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])\n",
    "    \n",
    "    elif branch == 'KCI':\n",
    "        \n",
    "        # update the 'kci' dictionary\n",
    "        kci_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])        \n",
    "        \n",
    "    else:\n",
    "        # update the 'oma' dictionary\n",
    "        oma_workflow_dict.update([('Claims Collected by Reps', rep_claim_collected_count),\n",
    "                                  ('Average Days to Collect', rep_claim_collected_avg_days)])\n",
    "\n",
    "print(den_workflow_dict)\n",
    "print(fco_workflow_dict)\n",
    "print(cos_workflow_dict)\n",
    "print(kci_workflow_dict)\n",
    "print(oma_workflow_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Building Department</th>\n",
       "      <th>City</th>\n",
       "      <th>Rep Agreement Signed</th>\n",
       "      <th>Rep Claim Collected</th>\n",
       "      <th>Rep Collecting Claim</th>\n",
       "      <th>FTA Scope Completed</th>\n",
       "      <th>Claim Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1287</th>\n",
       "      <td>300-0241517-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LITTLETON</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>2019-07-19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>01001445976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LONGMONT</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1344</th>\n",
       "      <td>3012670962-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>2019-04-18</td>\n",
       "      <td>2019-06-19</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>ICK2981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LITTLETON</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2019-03-28</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>040054040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-06-13</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>300-122-067-2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LITTLETON</td>\n",
       "      <td>2019-04-25</td>\n",
       "      <td>2019-05-06</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1937</th>\n",
       "      <td>069028C70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DENVER</td>\n",
       "      <td>2019-05-30</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>3012794091-1-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>KEENESBURG</td>\n",
       "      <td>2019-06-11</td>\n",
       "      <td>2019-06-25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dead</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Claim # Job # Branch Building Department        City  \\\n",
       "1287  300-0241517-2019   NaN    DEN                 NaN   LITTLETON   \n",
       "1338       01001445976   NaN    DEN                 NaN    LONGMONT   \n",
       "1344      3012670962-1   NaN    DEN                 NaN      DENVER   \n",
       "1773           ICK2981   NaN    DEN                 NaN   LITTLETON   \n",
       "1791         040054040   NaN    DEN                 NaN      DENVER   \n",
       "1910  300-122-067-2019   NaN    DEN                 NaN   LITTLETON   \n",
       "1937         069028C70   NaN    DEN                 NaN      DENVER   \n",
       "1980    3012794091-1-1   NaN    DEN                 NaN  KEENESBURG   \n",
       "\n",
       "     Rep Agreement Signed Rep Claim Collected  Rep Collecting Claim  \\\n",
       "1287           2019-07-18          2019-07-19                   1.0   \n",
       "1338           2019-04-18          2019-05-01                  13.0   \n",
       "1344           2019-04-18          2019-06-19                  62.0   \n",
       "1773           2019-03-20          2019-03-28                   8.0   \n",
       "1791           2019-05-30          2019-06-13                  14.0   \n",
       "1910           2019-04-25          2019-05-06                  11.0   \n",
       "1937           2019-05-30          2019-07-01                  32.0   \n",
       "1980           2019-06-11          2019-06-25                  14.0   \n",
       "\n",
       "     FTA Scope Completed Claim Status  \n",
       "1287                 NaT         Dead  \n",
       "1338                 NaT         Dead  \n",
       "1344                 NaT         Dead  \n",
       "1773                 NaT         Dead  \n",
       "1791                 NaT         Dead  \n",
       "1910                 NaT         Dead  \n",
       "1937                 NaT         Dead  \n",
       "1980                 NaT         Dead  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# separating the df into 'DEN'es according to the ''DEN'es' list\n",
    "branch_rep_claim_analysis = rep_claim_analysis_df.loc[rep_claim_analysis_df['Branch'] == 'DEN', :]\n",
    "\n",
    "# determining how many claim #s have been collected, 'dead' or not\n",
    "rep_claim_collected_count = branch_rep_claim_analysis['Rep Claim Collected'].count()\n",
    "\n",
    "# determining the average amount of days to collect claim, 'dead' or not\n",
    "rep_claim_collected_avg_days = round(branch_rep_claim_analysis['Rep Collecting Claim'].mean(), 2)\n",
    "\n",
    "# determing the count of 'dead' jobs per 'DEN'\n",
    "\n",
    "rep_claims_dead_analysis = branch_rep_claim_analysis.loc[(branch_rep_claim_analysis['Claim Status'] == 'Dead' ) & (branch_rep_claim_analysis['FTA Scope Completed'].isnull() == True), : ]\n",
    "\n",
    "# rep_claims_dead_analysis = (branch_rep_claim_analysis.loc[(branch_rep_claim_analysis['Claim Status'] == 'Dead') & \n",
    "#                                                           (branch_rep_claim_analysis['FTA Scope Completed'].isnull()) == True), :])\n",
    "\n",
    "# rep_claim_dead_count = rep_claims_dead_analysis['Claim Status'].count()\n",
    "\n",
    "rep_claims_dead_analysis.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## FTA Scope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with FTA Scope: 2015\n",
      "Quantile: 12.0\n",
      "Cleaned Records: 1813\n",
      "Outlier Records: 202\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'fta scope days'\n",
    "fta_quantile = workflow_table_df['FTA Completing Scope'].quantile(.90)\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "fta_scope_df = workflow_table_df.loc[(workflow_table_df['FTA Completing Scope'] >= 0) & (\n",
    "    workflow_table_df['FTA Completing Scope'] <= fta_quantile), :]\n",
    "\n",
    "# creating a fta scope outlier df\n",
    "outlier_fta_scope_df = workflow_table_df.loc[(workflow_table_df['FTA Completing Scope'] < 0) | (\n",
    "    workflow_table_df['FTA Completing Scope'] > fta_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with FTA Scope: {workflow_table_df['FTA Completing Scope'].count()}\")\n",
    "print(f\"Quantile: {fta_quantile}\")\n",
    "print(f\"Cleaned Records: {len(fta_scope_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_fta_scope_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Outlier Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# outlier_fta_scope_df['FTA Completing Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    593\n",
       "True     276\n",
       "Name: Multi-rejected, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# information to be combined with the rep data from 'project_table_df'\n",
    "fta_scope_project_analysis_df = project_table_df[['Claim #', 'Job #', 'Branch', \n",
    "                                                  'Claim Status', 'Rep Claim Collected', \n",
    "                                                  'FTA Scope Completed', 'FTA Scope Rejected']]\n",
    "\n",
    "# information to be combined with the rep data from 'project_info_df'\n",
    "fta_scope_info_analysis_df = project_info_df[['Claim #', 'Job #', \n",
    "                                              'City', 'Building Department','Multi-rejected',\n",
    "                                              'Scope Rejections']]\n",
    "\n",
    "# information to be combined with the rep data from 'workflow_table_df'\n",
    "fta_scope_workflow_analysis_df = workflow_table_df[['Claim #', 'FTA Completing Scope']]\n",
    "\n",
    "\n",
    "# merging all of the dfs together to prepare rep claim analysis\n",
    "fta_scope_analysis_df = fta_scope_project_analysis_df.merge(\n",
    "    fta_scope_info_analysis_df, on=[\"Claim #\", \"Job #\"]).merge(\n",
    "    fta_scope_workflow_analysis_df, on=['Claim #'])\n",
    "\n",
    "# organizing the df\n",
    "fta_scope_analysis_df = fta_scope_analysis_df[['Claim #','Job #','Branch',\n",
    "                                               'Building Department','City','Rep Claim Collected',\n",
    "                                               'FTA Scope Completed', 'FTA Scope Rejected','FTA Completing Scope',\n",
    "                                               'Scope Rejections', 'Multi-rejected','Claim Status']]\n",
    "\n",
    "\n",
    "fta_scope_analysis_df = fta_scope_analysis_df.loc[fta_scope_analysis_df['FTA Scope Completed'].notnull()==True,:]\n",
    "\n",
    "\n",
    "fta_scope_analysis_df[\"Multi-rejected\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Claim #</th>\n",
       "      <th>Job #</th>\n",
       "      <th>Branch</th>\n",
       "      <th>Building Department</th>\n",
       "      <th>City</th>\n",
       "      <th>Rep Claim Collected</th>\n",
       "      <th>FTA Scope Completed</th>\n",
       "      <th>FTA Scope Rejected</th>\n",
       "      <th>FTA Completing Scope</th>\n",
       "      <th>Scope Rejections</th>\n",
       "      <th>Multi-rejected</th>\n",
       "      <th>Claim Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00140067991A028</td>\n",
       "      <td>1938689</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Denver</td>\n",
       "      <td>2019-07-18</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>040357502</td>\n",
       "      <td>1938476</td>\n",
       "      <td>FCO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fort collins</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01001691605</td>\n",
       "      <td>1938472</td>\n",
       "      <td>DEN</td>\n",
       "      <td>Westminster, City of (DEN)</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>020487835-7</td>\n",
       "      <td>1938470</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Westminster</td>\n",
       "      <td>2019-07-15</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>NaT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23255128-002</td>\n",
       "      <td>1938447</td>\n",
       "      <td>OMA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Claim #    Job # Branch         Building Department          City  \\\n",
       "0  00140067991A028  1938689    DEN                         NaN        Denver   \n",
       "1        040357502  1938476    FCO                         NaN  fort collins   \n",
       "2      01001691605  1938472    DEN  Westminster, City of (DEN)   Westminster   \n",
       "3      020487835-7  1938470    DEN                         NaN   Westminster   \n",
       "4     23255128-002  1938447    OMA                         NaN         Omaha   \n",
       "\n",
       "  Rep Claim Collected FTA Scope Completed FTA Scope Rejected  \\\n",
       "0          2019-07-18          2019-07-20         2019-07-23   \n",
       "1          2019-07-15          2019-07-22                NaT   \n",
       "2          2019-07-15          2019-07-17                NaT   \n",
       "3          2019-07-15          2019-07-16                NaT   \n",
       "4          2019-07-16          2019-07-17         2019-07-23   \n",
       "\n",
       "   FTA Completing Scope  Scope Rejections Multi-rejected Claim Status  \n",
       "0                   5.0               1.0          False          NaN  \n",
       "1                   7.0               NaN            NaN          NaN  \n",
       "2                   2.0               NaN            NaN          NaN  \n",
       "3                   1.0               NaN            NaN          NaN  \n",
       "4                   7.0               1.0          False          NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fta_scope_analysis_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Estimate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Estimate: 1969\n",
      "Quantile: 2.0\n",
      "Cleaned Records: 1793\n",
      "Outlier Records: 176\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'rep claim days'\n",
    "bc_quantile = workflow_table_df['BC Completing Estimate'].quantile(.90)\n",
    "num_bc_estimates = workflow_table_df['BC Completing Estimate'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_estimate_df = workflow_table_df.loc[(workflow_table_df['BC Completing Estimate'] >= 0) & (\n",
    "    workflow_table_df['BC Completing Estimate'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc estimate outlier df\n",
    "outlier_bc_estimate_df = workflow_table_df.loc[(workflow_table_df['BC Completing Estimate'] < 0) | (\n",
    "    workflow_table_df['BC Completing Estimate'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Estimate: {workflow_table_df['BC Completing Estimate'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")\n",
    "print(f\"Cleaned Records: {len(bc_estimate_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_estimate_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 3.0     116\n",
       " 4.0      21\n",
       " 5.0      11\n",
       " 6.0       7\n",
       " 10.0      3\n",
       " 7.0       3\n",
       " 8.0       3\n",
       "-1.0       2\n",
       " 12.0      1\n",
       "-4.0       1\n",
       " 17.0      1\n",
       " 14.0      1\n",
       " 13.0      1\n",
       " 9.0       1\n",
       "-7.0       1\n",
       " 23.0      1\n",
       "-2.0       1\n",
       "-3.0       1\n",
       "Name: BC Completing Estimate, dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_estimate_df['BC Completing Estimate'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OB Scope Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with OB Scope: 1865\n",
      "Quantile: 6.0\n",
      "Cleaned Records: 1711\n",
      "Outlier Records: 154\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ob scoped days'\n",
    "ob_quantile = workflow_table_df['OB Completing Scope'].quantile(.90)\n",
    "num_ob_scopes = workflow_table_df['OB Completing Scope'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ob_scope_df = workflow_table_df.loc[(workflow_table_df['OB Completing Scope'] >= 0) & (\n",
    "    workflow_table_df['OB Completing Scope'] <= ob_quantile), :]\n",
    "\n",
    "# creating a ob scoped outlier df\n",
    "outlier_ob_scope_df = workflow_table_df.loc[(workflow_table_df['OB Completing Scope'] < 0) | (\n",
    "    workflow_table_df['OB Completing Scope'] > ob_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with OB Scope: {workflow_table_df['OB Completing Scope'].count()}\")\n",
    "print(f\"Quantile: {ob_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ob_scope_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ob_scope_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 7.0     59\n",
       " 8.0     22\n",
       " 10.0    13\n",
       " 9.0     11\n",
       "-1.0     11\n",
       " 11.0    11\n",
       " 12.0     8\n",
       " 13.0     4\n",
       "-4.0      3\n",
       "-2.0      2\n",
       " 16.0     1\n",
       " 25.0     1\n",
       " 17.0     1\n",
       " 15.0     1\n",
       "-34.0     1\n",
       "-7.0      1\n",
       " 87.0     1\n",
       " 14.0     1\n",
       "-5.0      1\n",
       " 49.0     1\n",
       "Name: OB Completing Scope, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ob_scope_df['OB Completing Scope'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# will want to see what is causing the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "outlier_ob_scope_df.to_csv(\"data/outliers/ob_scope_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sup Submittal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Sup Submit: 1191\n",
      "Quantile: 22.0\n",
      "Cleaned Records: 1078\n",
      "Outlier Records: 113\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'sup submitted days'\n",
    "sup_quantile = workflow_table_df['Sup Submitting Job'].quantile(.90)\n",
    "num_sup_submits = workflow_table_df['Sup Submitting Job'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "sup_submit_df = workflow_table_df.loc[(workflow_table_df['Sup Submitting Job'] >= 0) & (\n",
    "    workflow_table_df['Sup Submitting Job'] <= sup_quantile), :]\n",
    "\n",
    "# creating a sup submitted outlier df\n",
    "outlier_sup_submit_df = workflow_table_df.loc[(workflow_table_df['Sup Submitting Job'] < 0) | (\n",
    "    workflow_table_df['Sup Submitting Job'] > sup_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Sup Submit: {workflow_table_df['Sup Submitting Job'].count()}\")\n",
    "print(f\"Quantile: {sup_quantile}\")\n",
    "print(f\"Cleaned Records: {len(sup_submit_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_sup_submit_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 23.0    13\n",
       " 27.0    10\n",
       " 33.0     8\n",
       " 34.0     7\n",
       " 24.0     6\n",
       " 38.0     5\n",
       " 37.0     4\n",
       " 26.0     4\n",
       " 28.0     3\n",
       " 29.0     3\n",
       " 56.0     3\n",
       " 40.0     3\n",
       " 39.0     3\n",
       " 35.0     3\n",
       " 31.0     3\n",
       " 43.0     3\n",
       " 25.0     3\n",
       " 30.0     2\n",
       "-2.0      2\n",
       " 41.0     2\n",
       "-4.0      2\n",
       " 42.0     2\n",
       " 36.0     2\n",
       " 51.0     2\n",
       " 45.0     2\n",
       " 46.0     2\n",
       " 44.0     1\n",
       " 32.0     1\n",
       " 50.0     1\n",
       " 61.0     1\n",
       " 49.0     1\n",
       " 62.0     1\n",
       " 48.0     1\n",
       "-5.0      1\n",
       " 60.0     1\n",
       "-10.0     1\n",
       " 66.0     1\n",
       "Name: Sup Submitting Job, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_sup_submit_df['Sup Submitting Job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Approval Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Approval: 1118\n",
      "Quantile: 8.300000000000068\n",
      "Cleaned Records: 1003\n",
      "Outlier Records: 115\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc approved days'\n",
    "bc_quantile = workflow_table_df['BC Approving Job'].quantile(.90)\n",
    "num_bc_approvals = workflow_table_df['BC Approving Job'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_approval_df = workflow_table_df.loc[(workflow_table_df['BC Approving Job'] >= 0) & (\n",
    "    workflow_table_df['BC Approving Job'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc approved outlier df\n",
    "outlier_bc_approval_df = workflow_table_df.loc[(workflow_table_df['BC Approving Job'] < 0) | (\n",
    "    workflow_table_df['BC Approving Job'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Approval: {workflow_table_df['BC Approving Job'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")\n",
    "print(f\"Cleaned Records: {len(bc_approval_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_approval_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 13.0    15\n",
       " 9.0     14\n",
       " 12.0    13\n",
       " 11.0    12\n",
       " 20.0     8\n",
       " 19.0     7\n",
       " 14.0     5\n",
       " 26.0     5\n",
       " 10.0     4\n",
       " 17.0     4\n",
       " 21.0     4\n",
       " 25.0     4\n",
       " 18.0     3\n",
       " 16.0     3\n",
       " 23.0     2\n",
       " 15.0     2\n",
       " 27.0     1\n",
       " 41.0     1\n",
       " 35.0     1\n",
       "-11.0     1\n",
       " 39.0     1\n",
       " 29.0     1\n",
       "-13.0     1\n",
       " 32.0     1\n",
       "-4.0      1\n",
       " 46.0     1\n",
       "Name: BC Approving Job, dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_approval_df['BC Approving Job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## OB Create Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with OB Order: 1085\n",
      "Quantile: 5.0\n",
      "Cleaned Records: 990\n",
      "Outlier Records: 95\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ob created days'\n",
    "ob_quantile = workflow_table_df['OB Building Order'].quantile(.90)\n",
    "num_ob_orders = workflow_table_df['OB Building Order'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ob_order_df = workflow_table_df.loc[(workflow_table_df['OB Building Order'] >= 0) & (\n",
    "    workflow_table_df['OB Building Order'] <= ob_quantile), :]\n",
    "\n",
    "# creating a ob created outlier df\n",
    "outlier_ob_order_df = workflow_table_df.loc[(workflow_table_df['OB Building Order'] < 0) | (\n",
    "    workflow_table_df['OB Building Order'] > ob_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with OB Order: {workflow_table_df['OB Building Order'].count()}\")\n",
    "print(f\"Quantile: {ob_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ob_order_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ob_order_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 7.0     15\n",
       " 6.0     14\n",
       " 11.0    12\n",
       " 8.0      9\n",
       " 10.0     9\n",
       " 9.0      9\n",
       " 12.0     7\n",
       " 13.0     4\n",
       " 15.0     4\n",
       " 20.0     4\n",
       " 16.0     2\n",
       "-9.0      1\n",
       " 53.0     1\n",
       " 27.0     1\n",
       " 28.0     1\n",
       " 24.0     1\n",
       " 40.0     1\n",
       "Name: OB Building Order, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ob_order_df['OB Building Order'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GM Process Order Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with GM Processed Order: 884\n",
      "Quantile: 20.0\n",
      "Cleaned Records: 796\n",
      "Outlier Records: 88\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'gm processed days'\n",
    "gm_quantile = workflow_table_df['GM Processing Order'].quantile(.90)\n",
    "num_gm_orders = workflow_table_df['GM Processing Order'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "gm_order_df = workflow_table_df.loc[(workflow_table_df['GM Processing Order'] >= 0) & (\n",
    "    workflow_table_df['GM Processing Order'] <= gm_quantile), :]\n",
    "\n",
    "# creating a gm processed outlier df\n",
    "outlier_gm_order_df = workflow_table_df.loc[(workflow_table_df['GM Processing Order'] < 0) | (\n",
    "    workflow_table_df['GM Processing Order'] > gm_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with GM Processed Order: {workflow_table_df['GM Processing Order'].count()}\")\n",
    "print(f\"Quantile: {gm_quantile}\")\n",
    "print(f\"Cleaned Records: {len(gm_order_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_gm_order_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 21.0    12\n",
       " 22.0     9\n",
       " 29.0     8\n",
       " 27.0     7\n",
       " 28.0     7\n",
       " 24.0     7\n",
       " 30.0     5\n",
       " 23.0     4\n",
       " 38.0     3\n",
       " 34.0     3\n",
       " 36.0     3\n",
       " 25.0     2\n",
       " 41.0     2\n",
       " 26.0     2\n",
       " 42.0     2\n",
       " 47.0     1\n",
       " 60.0     1\n",
       "-7.0      1\n",
       " 40.0     1\n",
       " 35.0     1\n",
       " 55.0     1\n",
       " 46.0     1\n",
       " 63.0     1\n",
       " 54.0     1\n",
       " 37.0     1\n",
       " 43.0     1\n",
       " 32.0     1\n",
       "Name: GM Processing Order, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_gm_order_df['GM Processing Order'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# will want to determine what is causing the outliers\n",
    "outlier_gm_order_df.to_csv(\"data_copy/outliers/gm_order_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PA Process OA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with PA OA Processed: 827\n",
      "Quantile: 3.0\n",
      "Cleaned Records: 756\n",
      "Outlier Records: 71\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'pa oa processeddays'\n",
    "pa_quantile = workflow_table_df['PA Processing OA'].quantile(.90)\n",
    "num_pa_oa_processed = workflow_table_df['PA Processing OA'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "pa_processed_oa_df = workflow_table_df.loc[(workflow_table_df['PA Processing OA'] >= 0) & (\n",
    "    workflow_table_df['PA Processing OA'] <= pa_quantile), :]\n",
    "\n",
    "# creating a pa oa processedoutlier df\n",
    "outlier_pa_processed_oa_df = workflow_table_df.loc[(workflow_table_df['PA Processing OA'] < 0) | (\n",
    "    workflow_table_df['PA Processing OA'] > pa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with PA OA Processed: {workflow_table_df['PA Processing OA'].count()}\")\n",
    "print(f\"Quantile: {pa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(pa_processed_oa_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_pa_processed_oa_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 4.0     24\n",
       " 5.0     20\n",
       " 6.0      7\n",
       " 10.0     4\n",
       " 7.0      2\n",
       " 11.0     2\n",
       " 8.0      2\n",
       " 30.0     1\n",
       " 17.0     1\n",
       " 12.0     1\n",
       "-10.0     1\n",
       " 20.0     1\n",
       " 14.0     1\n",
       " 15.0     1\n",
       "-1.0      1\n",
       " 42.0     1\n",
       " 18.0     1\n",
       "Name: PA Processing OA, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_pa_processed_oa_df['PA Processing OA'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## PA Invoicing OA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with PA OA Invoiced: 714\n",
      "Quantile: 8.0\n",
      "Cleaned Records: 668\n",
      "Outlier Records: 46\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'pa oa invoiceddays'\n",
    "pa_quantile = workflow_table_df['PA Invoicing OA'].quantile(.90)\n",
    "num_pa_oa_invoiced = workflow_table_df['PA Invoicing OA'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "pa_invoiced_oa_df = workflow_table_df.loc[(workflow_table_df['PA Invoicing OA'] >= 0) & (\n",
    "    workflow_table_df['PA Invoicing OA'] <= pa_quantile), :]\n",
    "\n",
    "# creating a pa oa invoicedoutlier df\n",
    "outlier_pa_invoiced_oa_df = workflow_table_df.loc[(workflow_table_df['PA Invoicing OA'] < 0) | (\n",
    "    workflow_table_df['PA Invoicing OA'] > pa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with PA OA Invoiced: {workflow_table_df['PA Invoicing OA'].count()}\")\n",
    "print(f\"Quantile: {pa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(pa_invoiced_oa_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_pa_invoiced_oa_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.0    14\n",
       "9.0     10\n",
       "10.0     4\n",
       "15.0     3\n",
       "12.0     3\n",
       "19.0     3\n",
       "13.0     2\n",
       "33.0     1\n",
       "21.0     1\n",
       "20.0     1\n",
       "18.0     1\n",
       "14.0     1\n",
       "16.0     1\n",
       "28.0     1\n",
       "Name: PA Invoicing OA, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_pa_invoiced_oa_df['PA Invoicing OA'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_pa_invoiced_oa_df.to_csv(\"data_copy/outliers/pa_invoiced_oa_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## GM Approving for Inspection Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with GM Approved for Inspection: 645\n",
      "Quantile: 3.0\n",
      "Cleaned Records: 587\n",
      "Outlier Records: 58\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'gm approved for inspection days'\n",
    "gm_quantile = workflow_table_df['GM Approving for Inspection'].quantile(.90)\n",
    "num_gm_approved_inspection = workflow_table_df['GM Approving for Inspection'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "gm_approved_inspection_df = workflow_table_df.loc[(workflow_table_df['GM Approving for Inspection'] >= 0) & (\n",
    "    workflow_table_df['GM Approving for Inspection'] <= gm_quantile), :]\n",
    "\n",
    "# creating a gm approved for inspection outlier df\n",
    "outlier_gm_approved_inspection_df = workflow_table_df.loc[(workflow_table_df['GM Approving for Inspection'] < 0) | (\n",
    "    workflow_table_df['GM Approving for Inspection'] > gm_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with GM Approved for Inspection: {workflow_table_df['GM Approving for Inspection'].count()}\")\n",
    "print(f\"Quantile: {gm_quantile}\")\n",
    "print(f\"Cleaned Records: {len(gm_approved_inspection_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_gm_approved_inspection_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0     26\n",
       "5.0     17\n",
       "6.0     13\n",
       "30.0     1\n",
       "8.0      1\n",
       "Name: GM Approving for Inspection, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_gm_approved_inspection_df['GM Approving for Inspection'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_gm_approved_inspection_df.to_csv(\"data_copy/outliers/gm_approved_inspection_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## RA Requesting Inspection Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with RA Requested Inspection: 280\n",
      "Quantile: 18.0\n",
      "Cleaned Records: 254\n",
      "Outlier Records: 26\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'ra requesting inspection days'\n",
    "ra_quantile = workflow_table_df['RA Requesting Inspection'].quantile(.90)\n",
    "num_ra_requested = workflow_table_df['RA Requesting Inspection'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "ra_requested_inspection_df = workflow_table_df.loc[(workflow_table_df['RA Requesting Inspection'] >= 0) & (\n",
    "    workflow_table_df['RA Requesting Inspection'] <= ra_quantile), :]\n",
    "\n",
    "# creating a ra requesting inspection outlier df\n",
    "outlier_ra_requested_inspection_df = workflow_table_df.loc[(workflow_table_df['RA Requesting Inspection'] < 0) | (\n",
    "    workflow_table_df['RA Requesting Inspection'] > ra_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with RA Requested Inspection: {workflow_table_df['RA Requesting Inspection'].count()}\")\n",
    "print(f\"Quantile: {ra_quantile}\")\n",
    "print(f\"Cleaned Records: {len(ra_requested_inspection_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_ra_requested_inspection_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0    4\n",
       "20.0    3\n",
       "25.0    3\n",
       "27.0    2\n",
       "22.0    2\n",
       "26.0    1\n",
       "21.0    1\n",
       "42.0    1\n",
       "36.0    1\n",
       "45.0    1\n",
       "67.0    1\n",
       "24.0    1\n",
       "28.0    1\n",
       "61.0    1\n",
       "47.0    1\n",
       "31.0    1\n",
       "41.0    1\n",
       "Name: RA Requesting Inspection, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_ra_requested_inspection_df['RA Requesting Inspection'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Rep Collecting COC Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with Rep COC Collected: 615\n",
      "Quantile: 15.0\n",
      "Cleaned Records: 556\n",
      "Outlier Records: 59\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'rep collect coc days'\n",
    "rep_quantile = workflow_table_df['Rep Collecting COC'].quantile(.90)\n",
    "num_rep_collected = workflow_table_df['Rep Collecting COC'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "rep_collected_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting COC'] >= 0) & (\n",
    "    workflow_table_df['Rep Collecting COC'] <= rep_quantile), :]\n",
    "\n",
    "# creating a rep collect coc outlier df\n",
    "outlier_rep_collected_df = workflow_table_df.loc[(workflow_table_df['Rep Collecting COC'] < 0) | (\n",
    "    workflow_table_df['Rep Collecting COC'] > rep_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with Rep COC Collected: {workflow_table_df['Rep Collecting COC'].count()}\")\n",
    "print(f\"Quantile: {rep_quantile}\")\n",
    "print(f\"Cleaned Records: {len(rep_collected_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_rep_collected_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.0    10\n",
       "20.0     6\n",
       "19.0     4\n",
       "23.0     4\n",
       "17.0     4\n",
       "24.0     3\n",
       "22.0     3\n",
       "35.0     2\n",
       "21.0     2\n",
       "26.0     2\n",
       "33.0     2\n",
       "18.0     2\n",
       "37.0     2\n",
       "28.0     2\n",
       "29.0     1\n",
       "47.0     1\n",
       "43.0     1\n",
       "25.0     1\n",
       "62.0     1\n",
       "46.0     1\n",
       "34.0     1\n",
       "50.0     1\n",
       "32.0     1\n",
       "49.0     1\n",
       "30.0     1\n",
       "Name: Rep Collecting COC, dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_rep_collected_df['Rep Collecting COC'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Want to see what is causing the outliers\n",
    "outlier_rep_collected_df.to_csv(\"data_copy/outliers/rep_collected_outlier_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## SA Uploading Docs Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with SA Docs Uploaded: 522\n",
      "Quantile: 16.0\n",
      "Cleaned Records: 473\n",
      "Outlier Records: 49\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'sa uploaded days'\n",
    "sa_quantile = workflow_table_df['SA Uploading Docs'].quantile(.90)\n",
    "num_sa_uploaded = workflow_table_df['SA Uploading Docs'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "sa_uploaded_df = workflow_table_df.loc[(workflow_table_df['SA Uploading Docs'] >= 0) & (\n",
    "    workflow_table_df['SA Uploading Docs'] <= sa_quantile), :]\n",
    "\n",
    "# creating a sa uploaded outlier df\n",
    "outlier_sa_uploaded_df = workflow_table_df.loc[(workflow_table_df['SA Uploading Docs'] < 0) | (\n",
    "    workflow_table_df['SA Uploading Docs'] > sa_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with SA Docs Uploaded: {workflow_table_df['SA Uploading Docs'].count()}\")\n",
    "print(f\"Quantile: {sa_quantile}\")\n",
    "print(f\"Cleaned Records: {len(sa_uploaded_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_sa_uploaded_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0    8\n",
       "26.0    5\n",
       "19.0    4\n",
       "25.0    4\n",
       "32.0    3\n",
       "24.0    3\n",
       "18.0    3\n",
       "27.0    3\n",
       "28.0    2\n",
       "37.0    2\n",
       "23.0    2\n",
       "20.0    2\n",
       "17.0    2\n",
       "22.0    1\n",
       "54.0    1\n",
       "33.0    1\n",
       "29.0    1\n",
       "44.0    1\n",
       "71.0    1\n",
       "Name: SA Uploading Docs, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_sa_uploaded_df['SA Uploading Docs'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Invoicing Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Project Invoiced: 464\n",
      "Quantile: 9.0\n",
      "Cleaned Records: 422\n",
      "Outlier Records: 42\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc invoiced days'\n",
    "bc_quantile = workflow_table_df['BC Invoicing Project'].quantile(.90)\n",
    "num_bc_invoiced = workflow_table_df['BC Invoicing Project'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_invoiced_df = workflow_table_df.loc[(workflow_table_df['BC Invoicing Project'] >= 0) & (\n",
    "    workflow_table_df['BC Invoicing Project'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc invoiced outlier df\n",
    "outlier_bc_invoiced_df = workflow_table_df.loc[(workflow_table_df['BC Invoicing Project'] < 0) | (\n",
    "    workflow_table_df['BC Invoicing Project'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Project Invoiced: {workflow_table_df['BC Invoicing Project'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")      \n",
    "print(f\"Cleaned Records: {len(bc_invoiced_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_invoiced_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.0    7\n",
       "15.0    6\n",
       "10.0    6\n",
       "12.0    5\n",
       "11.0    5\n",
       "16.0    3\n",
       "17.0    3\n",
       "13.0    3\n",
       "18.0    2\n",
       "21.0    1\n",
       "20.0    1\n",
       "Name: BC Invoicing Project, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_invoiced_df['BC Invoicing Project'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BC Closed Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow Records with BC Project Closed: 237\n",
      "Quantile: 41.0\n",
      "Cleaned Records: 216\n",
      "Outlier Records: 21\n"
     ]
    }
   ],
   "source": [
    "# created a variable to be able to allow a 10% error in 'bc closed days'\n",
    "bc_quantile = workflow_table_df['BC Closed Project'].quantile(.90)\n",
    "num_bc_closed = workflow_table_df['BC Closed Project'].count()\n",
    "\n",
    "# produce only positive day claims within 90% of all records\n",
    "bc_closed_df = workflow_table_df.loc[(workflow_table_df['BC Closed Project'] >= 0) & (\n",
    "    workflow_table_df['BC Closed Project'] <= bc_quantile), :]\n",
    "\n",
    "# creating a bc closed outlier df\n",
    "outlier_bc_closed_df = workflow_table_df.loc[(workflow_table_df['BC Closed Project'] < 0) | (\n",
    "    workflow_table_df['BC Closed Project'] > bc_quantile), :]\n",
    "\n",
    "# confirming no records were lost\n",
    "print(f\"Workflow Records with BC Project Closed: {workflow_table_df['BC Closed Project'].count()}\")\n",
    "print(f\"Quantile: {bc_quantile}\")      \n",
    "print(f\"Cleaned Records: {len(bc_closed_df)}\")\n",
    "print(f\"Outlier Records: {len(outlier_bc_closed_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.0    2\n",
       "49.0    2\n",
       "51.0    2\n",
       "43.0    2\n",
       "47.0    2\n",
       "48.0    1\n",
       "69.0    1\n",
       "78.0    1\n",
       "67.0    1\n",
       "63.0    1\n",
       "70.0    1\n",
       "77.0    1\n",
       "71.0    1\n",
       "68.0    1\n",
       "50.0    1\n",
       "42.0    1\n",
       "Name: BC Closed Project, dtype: int64"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_bc_closed_df['BC Closed Project'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "300.521px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "695.208px",
    "left": "830px",
    "right": "20px",
    "top": "120px",
    "width": "314.774px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
