{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports the '[TVA] Workflow Analysis' data\n",
    "all_project_data = \"./data/trackvia_data/workflow_analysis.csv\"\n",
    "\n",
    "# imports the '[TVA] Project Workflow Analysis' data\n",
    "all_production_data = \"./data/trackvia_data/project_workflow_analysis.csv\"\n",
    "\n",
    "# imports '[TVA] Project Info Analysis' data\n",
    "info_data = \"./data/trackvia_data/info_table.csv\"\n",
    "\n",
    "# imports '[TVA] FTA Scope Analysis' data\n",
    "rejection_data = \"./data/trackvia_data/rejection_table.csv\"\n",
    "\n",
    "# imports the 'oa processed' PA data currently being tracked\n",
    "oa_processed_data = \"./data/tracker_data/oa_processed.csv\"\n",
    "\n",
    "# imports the 'oa invoiced' PA data currently being tracked\n",
    "oa_invoiced_data = \"./data/tracker_data/oa_invoiced.csv\"\n",
    "\n",
    "# imports '[TVA] GM Change Order Analysis' data\n",
    "change_order_data = \"./data/trackvia_data/change_orders.csv\"\n",
    "\n",
    "# imports '[TVA] GM Labor Order Adjustment Analysis' data\n",
    "labor_adjustment_data = \"./data/trackvia_data/labor_adjustments.csv\"\n",
    "\n",
    "# imports the 'approved for inspection' GM data currently being tracked\n",
    "approved_for_inspection_data = \"./data/tracker_data/approved_for_inspection.csv\"\n",
    "\n",
    "# imports the '[TVA] Eagleview Analysis' data\n",
    "eagleview_data = \"./data/trackvia_data/eagleview_analysis.csv\"\n",
    "\n",
    "# imports the 'coc collected' SA data currently being tracked\n",
    "coc_collected_data = \"./data/tracker_data/coc_collected.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## function to create the 'info_df'\n",
    "def create_project_info_table():\n",
    "    info_df = pd.read_csv(info_data, dtype='str')\n",
    "    \n",
    "    return info_df\n",
    "\n",
    "########## function to create the 'project_df'\n",
    "def create_project_sales_table():\n",
    "\n",
    "    project_df = pd.read_csv(all_project_data, \n",
    "                             dtype={'Claim #': str, 'Job #': str, 'Branch': str, 'Claim Status': str}, \n",
    "                             parse_dates=['Claim # Date', 'FTA Scope. Req Date', 'Submit for Estimate Date',\n",
    "                                          '[OB] Created Scope Calc', '[B] Created Estimate Date',\n",
    "                                          'Job Submittal Date', '[B] - Date Approved by BC', '[OB] Completed',\n",
    "                                          'COC Rcvd Date [A]', 'Job Docs Scanned', \n",
    "                                          '[B] Sent Invoice Packet to Ins Co','[B] Settled with Insurance'])\n",
    "\n",
    "    # having trouble recognizing 'coc' date as 'datetime', manually converted the dtype.\n",
    "    project_df['COC Rcvd Date [A]'] = pd.to_datetime(project_df['COC Rcvd Date [A]'], errors='coerce')\n",
    "    \n",
    "    # storing all floored timestamps in a list\n",
    "    floored_ob_order_builds = []\n",
    "\n",
    "    # iterating over the 'project_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in project_df.iterrows():\n",
    "\n",
    "        # zeroing out the hours and minutes, appending value to 'floored' list\n",
    "        ob_order_builds = row['[OB] Completed'].replace(hour=0, minute=0)\n",
    "        floored_ob_order_builds.append(ob_order_builds)\n",
    "\n",
    "    # adding the floored list to the 'project_df'\n",
    "    project_df['[OB] Completed'] = floored_ob_order_builds\n",
    "    \n",
    "    return project_df\n",
    "\n",
    "########## function to create the 'production_df'\n",
    "def create_project_production_table():\n",
    "    \n",
    "    production_df = pd.read_csv(\n",
    "        all_production_data, \n",
    "        dtype={'Job #': str,'Supplier Name': str,'Building Department': str,'Permit Req?': str},\n",
    "        parse_dates=['Permit Applied [A]','Order Date','Permit Received','OA Date','Invoice Date',\n",
    "                 'Ntfd H.O. Dlvry','Dlvry Start','Ntfd H.O. Start','Roof Start','Roof Complete Date',\n",
    "                 'R4F','Requested Final Insp','Final Inspection Date'])\n",
    "    \n",
    "    # storing all floored timestamps in a list\n",
    "    floored_pa_oa_processed = []\n",
    "\n",
    "    # iterating over the 'production_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in production_df.iterrows():\n",
    "\n",
    "        # zeroing out the hours and minutes, appending value to 'floored' list\n",
    "        pa_oa_processed = row['OA Date'].replace(hour=0, minute=0)\n",
    "        floored_pa_oa_processed.append(pa_oa_processed)\n",
    "\n",
    "    # adding the floored list to the 'production_df'\n",
    "    production_df['OA Date'] = floored_pa_oa_processed\n",
    "\n",
    "    return production_df\n",
    "\n",
    "########## function to create the 'rejection_table_df'\n",
    "def create_rejection_table():\n",
    "    \n",
    "    rejection_table_df = pd.read_csv(rejection_data, dtype={'Claim #': str},parse_dates=['Created'])\n",
    "\n",
    "    # storing all floored timestamps in a list\n",
    "    floored_fta_rejections = []\n",
    "\n",
    "    # iterating over the 'rejection_table_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in rejection_table_df.iterrows():\n",
    "\n",
    "        # zeroing out the hours and minutes, appending value to 'floored' list\n",
    "        fta_rejections = row['Created'].replace(hour=0, minute=0)\n",
    "        floored_fta_rejections.append(fta_rejections)\n",
    "\n",
    "    # adding the floored list to the 'rejection_table_df'\n",
    "    rejection_table_df['Created'] = floored_fta_rejections\n",
    "    \n",
    "    ### Latest Rejection\n",
    "    # 'idmax()' of the 'Created' column provides the most current rejection date\n",
    "    reject_df = rejection_table_df.loc[rejection_table_df.groupby('Claim #')['Created'].idxmax()]\n",
    "    reject_df = reject_df.rename(columns={\"Created\": \"Most Recent Rejection\"})\n",
    "    \n",
    "    ###  Multi-Rejection Counts\n",
    "    rejection_count_df = (rejection_table_df.groupby(\"Claim #\").count())\n",
    "    rejection_count_df.reset_index(inplace=True)\n",
    "    rejection_count_df = rejection_count_df.rename(columns={\"Created\": \"Scope Rejections\"})\n",
    "    \n",
    "    #merging 'reject_df' with the scope rejection count(s)\n",
    "    scope_rejection_df = reject_df.merge(rejection_count_df, on='Claim #')\n",
    "    \n",
    "    return scope_rejection_df\n",
    "\n",
    "########## function to create the updated 'oa_processed_df'\n",
    "def create_oa_processed_updated_table():\n",
    "    oa_processed_df = pd.read_csv(oa_processed_data, dtype={'Job #': str}, parse_dates=['Updated'], usecols=['Job #', 'Updated'])\n",
    "\n",
    "    # storing all floored timestamps in a list\n",
    "    floored_oa_processed = []\n",
    "\n",
    "    # iterating over the 'oa_processed_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in oa_processed_df.iterrows():\n",
    "        adjusted_oa_processed = row['Updated'].replace(hour=0, minute=0)\n",
    "        floored_oa_processed.append(adjusted_oa_processed)\n",
    "\n",
    "    # adding the floored list to the 'oa_processed_df'\n",
    "    oa_processed_df['Updated'] = floored_oa_processed\n",
    "    oa_processed_df = oa_processed_df.rename(columns={'Updated':'Updated OA Processed'})\n",
    "\n",
    "    return oa_processed_df\n",
    "\n",
    "########## function to create the updated 'oa_invoiced_df'\n",
    "def create_oa_invoiced_updated_table():\n",
    "\n",
    "    oa_invoiced_df = pd.read_csv(oa_invoiced_data, dtype={'Job #': str}, parse_dates=['Updated'], usecols=['Job #', 'Updated'])\n",
    "\n",
    "    # storing all floored timestamps in a list\n",
    "    floored_oa_invoiced = []\n",
    "\n",
    "    # # iterating over the 'oa_invoiced_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in oa_invoiced_df.iterrows():\n",
    "        adjusted_oa_invoiced = row['Updated'].replace(hour=0, minute=0)\n",
    "        floored_oa_invoiced.append(adjusted_oa_invoiced)\n",
    "\n",
    "    # adding the floored list to the 'oa_invoiced_df'\n",
    "    oa_invoiced_df['Updated'] = floored_oa_invoiced\n",
    "    oa_invoiced_df = oa_invoiced_df.rename(columns={'Updated':'Updated OA Invoiced'})\n",
    "\n",
    "    return oa_invoiced_df\n",
    "\n",
    "########## function to create the 'approve_for_inspection_df'\n",
    "def create_approve_for_inspection_updated_table():\n",
    "    approve_for_inspection_df = pd.read_csv(approved_for_inspection_data, dtype={'Job #': str}, parse_dates=['Updated'], usecols=['Job #','Updated'])\n",
    "\n",
    "    # storing all floored timestamps in a list\n",
    "    floored_approve_for_inspection = []\n",
    "\n",
    "    # # iterating over the 'approve_for_inspection_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in approve_for_inspection_df.iterrows():\n",
    "        adjusted_approve_for_inspection = row['Updated'].replace(hour=0, minute=0)\n",
    "        floored_approve_for_inspection.append(adjusted_approve_for_inspection)\n",
    "\n",
    "    # adding the floored list to the 'approve_for_inspection_df'\n",
    "    approve_for_inspection_df['Updated'] = floored_approve_for_inspection\n",
    "    approve_for_inspection_df = approve_for_inspection_df.rename(columns={\"Updated\": \"Updated R4F\"})\n",
    "\n",
    "    return approve_for_inspection_df\n",
    "\n",
    "########## function to create the 'change_order_df'\n",
    "def create_change_order_table():\n",
    "    change_order_df = pd.read_csv(change_order_data, dtype={'Job #': str}, parse_dates=['Created'])\n",
    "    \n",
    "    # storing all floored timestamps in a list\n",
    "    floored_change_order = []\n",
    "\n",
    "    # iterating over the 'change_order_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in change_order_df.iterrows():\n",
    "\n",
    "        # zeroing out the hours and minutes, appending value to 'floored' list\n",
    "        gm_change_order = row['Created'].replace(hour=0, minute=0)\n",
    "        floored_change_order.append(gm_change_order)\n",
    "\n",
    "    # adding the floored list to the 'change_order_df'\n",
    "    change_order_df['Created'] = floored_change_order\n",
    "\n",
    "    # Change Order Date\n",
    "    co_date_df = change_order_df.loc[change_order_df.groupby('Job #')['Created'].idxmax()]\n",
    "    co_date_df = co_date_df.rename(columns={\"Created\": \"GM Change Order Date\"})\n",
    "\n",
    "    # Change Order Count\n",
    "    co_count_df = (change_order_df.groupby(\"Job #\").count())\n",
    "    co_count_df.reset_index(inplace=True)\n",
    "    co_count_df = co_count_df.rename(columns={\"Created\": \"Change Orders\"})\n",
    "\n",
    "    #merging 'co_date_df' with the change order count(s)\n",
    "    change_order_df = co_date_df.merge(co_count_df, on='Job #')\n",
    "\n",
    "    return change_order_df\n",
    "\n",
    "########## function to create the 'labor_adjustment_df'\n",
    "def create_labor_adjustment_table():\n",
    "\n",
    "    # GM Labor Adjustment Analysis\n",
    "    labor_adjustment_df = pd.read_csv(labor_adjustment_data, dtype={'Order ID': str}, parse_dates=['Created'])\n",
    "    \n",
    "    # storing all floored timestamps in a list\n",
    "    floored_labor_adjustment = []\n",
    "\n",
    "    # iterating over the 'labor_adjustment_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in labor_adjustment_df.iterrows():\n",
    "\n",
    "        # zeroing out the hours and minutes, appending value to 'floored' list\n",
    "        gm_labor_adjustment = row['Created'].replace(hour=0, minute=0)\n",
    "        floored_labor_adjustment.append(gm_labor_adjustment)\n",
    "\n",
    "    # adding the floored list to the 'labor_adjustment_df'\n",
    "    labor_adjustment_df['Created'] = floored_labor_adjustment\n",
    "\n",
    "    # list to store each 'job #' from string split\n",
    "    job_num_list = []\n",
    "\n",
    "    # splitting the 'order id' to get the job #\n",
    "    for index, row in labor_adjustment_df.iterrows():\n",
    "        job_num = row['Order ID'].split('-')[0]\n",
    "        job_num_list.append(job_num)\n",
    "\n",
    "    # creating a 'job #' column in the df\n",
    "    labor_adjustment_df['Job #'] = job_num_list\n",
    "    del labor_adjustment_df['Order ID']\n",
    "    \n",
    "    # Labor Adjustment Date\n",
    "    la_date_df = labor_adjustment_df.loc[labor_adjustment_df.groupby('Job #')['Created'].idxmax()]\n",
    "    la_date_df = la_date_df.rename(columns={\"Created\": \"GM Labor Adjustment Date\"})\n",
    "    \n",
    "    # Labor Adjustment Count\n",
    "    la_count_df = (labor_adjustment_df.groupby(\"Job #\").count())\n",
    "    la_count_df.reset_index(inplace=True)\n",
    "    la_count_df = la_count_df.rename(columns={\"Created\": \"Labor Adjustments\"})\n",
    "\n",
    "    #merging 'la_date_df' with the labor adjustment count(s)\n",
    "    labor_adjustment_df = la_count_df.merge(la_date_df, on='Job #')\n",
    "\n",
    "    return labor_adjustment_df\n",
    "\n",
    "########## function to create the updated 'coc_collected_df'\n",
    "def create_coc_updated_table():\n",
    "    coc_collected_df = pd.read_csv(coc_collected_data, dtype={'Job #': str}, parse_dates=['Updated'], usecols=['Claim #', 'Job #', 'Updated'])\n",
    "\n",
    "    # storing all floored timestamps in a list\n",
    "    floored_coc_collected = []\n",
    "\n",
    "    # iterating over the 'labor_adjustment_df' to 'floor' or zero out each timestamp\n",
    "    for index, row in coc_collected_df.iterrows():\n",
    "\n",
    "        # zeroing out the hours and minutes, appending value to 'floored' list\n",
    "        adjusted_coc_collected = row['Updated'].replace(hour=0, minute=0)\n",
    "        floored_coc_collected.append(adjusted_coc_collected)\n",
    "\n",
    "    # adding the floored list to the 'labor_adjustment_df'\n",
    "    coc_collected_df['Updated'] = floored_coc_collected\n",
    "    coc_collected_df = coc_collected_df.rename(columns={'Updated':'Updated COC Collected'})\n",
    "\n",
    "    return coc_collected_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### function for preparing the 'sales workflow' table ###############\n",
    "def cleanup_workflow_dates():\n",
    "    \n",
    "    # storing the table function dfs as variables\n",
    "    project_table = create_project_sales_table()\n",
    "    updated_coc_table = create_coc_updated_table()\n",
    "    \n",
    "    # merging the project and 'updated coc' data\n",
    "    cleanup_data = project_table.merge(updated_coc_table, how='left', on=['Claim #','Job #'])\n",
    "    \n",
    "    # list to store the correct coc dates\n",
    "    parsed_coc_dates = []\n",
    "    \n",
    "    for index, row in cleanup_data.iterrows():\n",
    "        \n",
    "        # if there is an 'updated coc collected' date...\n",
    "        if row['Updated COC Collected'] == row['Updated COC Collected']:\n",
    "            # use the updated coc date\n",
    "            real_coc_date = row['Updated COC Collected']\n",
    "            parsed_coc_dates.append(real_coc_date)\n",
    "\n",
    "        else:\n",
    "            # if not use the trackvia coc date\n",
    "            real_coc_date = row['COC Rcvd Date [A]']\n",
    "            parsed_coc_dates.append(real_coc_date)\n",
    "    \n",
    "    # save the new coc list as the official 'coc' list\n",
    "    cleanup_data['COC Rcvd Date [A]'] = parsed_coc_dates\n",
    "    \n",
    "    # delete the 'updated' coc column\n",
    "    del cleanup_data['Updated COC Collected']\n",
    "    \n",
    "    return cleanup_data\n",
    "\n",
    "############### function for preparing the 'production workflow' table ###############\n",
    "def cleanup_project_workflow_dates():\n",
    "    \n",
    "    # storing the table function dfs as variables\n",
    "    project_table = create_project_production_table()\n",
    "    updated_oa_processed_table = create_oa_processed_updated_table()\n",
    "    updated_oa_invoiced_table = create_oa_invoiced_updated_table()\n",
    "    updated_approved_for_inspection_table = create_approve_for_inspection_updated_table()\n",
    "    \n",
    "    # merging the 'oa_processed', 'oa_invoiced', and 'approved_for_inspection' tables\n",
    "    project_table = project_table.merge(\n",
    "        updated_oa_processed_table, how='left', on='Job #').merge(\n",
    "        updated_oa_invoiced_table, how='left', on='Job #').merge(\n",
    "        updated_approved_for_inspection_table, how='left', on='Job #')\n",
    "    \n",
    "    # lists to store the correct production dates\n",
    "    parsed_oa_processed_dates = []\n",
    "    parsed_oa_invoiced_dates = []\n",
    "    parsed_approved_for_inspection_dates = []\n",
    "    \n",
    "    for index, row in project_table.iterrows():\n",
    "        \n",
    "        # if there is an 'updated oa processed' date...\n",
    "        if row['Updated OA Processed'] == row['Updated OA Processed']:\n",
    "            # use the updated oa processed date\n",
    "            real_oa_processed_date = row['Updated OA Processed']\n",
    "            parsed_oa_processed_dates.append(real_oa_processed_date)\n",
    "        else:\n",
    "            # if not use the trackvia oa processed date\n",
    "            real_oa_processed_date = row['OA Date']\n",
    "            parsed_oa_processed_dates.append(real_oa_processed_date)\n",
    "        \n",
    "        \n",
    "        # if there is an 'updated oa invoiced' date...\n",
    "        if row['Updated OA Invoiced'] == row['Updated OA Invoiced']:\n",
    "            # use the updated oa invoiced date\n",
    "            real_oa_invoiced_date = row['Updated OA Invoiced']\n",
    "            parsed_oa_invoiced_dates.append(real_oa_invoiced_date)\n",
    "        else:\n",
    "            # if not use the trackvia oa invoiced date\n",
    "            real_oa_invoiced_date = row['Invoice Date']\n",
    "            parsed_oa_invoiced_dates.append(real_oa_invoiced_date)\n",
    "        \n",
    "        \n",
    "        # if there is an 'updated approved for inspection' date...\n",
    "        if row['Updated R4F'] == row['Updated R4F']:\n",
    "            real_approved_for_inspection_date = row['Updated R4F']\n",
    "            parsed_approved_for_inspection_dates.append(real_approved_for_inspection_date)\n",
    "        else:\n",
    "            # if not use the trackvia oa invoiced date\n",
    "            real_approved_for_inspection_date = row['R4F']\n",
    "            parsed_approved_for_inspection_dates.append(real_approved_for_inspection_date)\n",
    "            \n",
    "            \n",
    "    # save the new lists as on the production table before iterating workflow days\n",
    "    project_table['OA Date'] = parsed_oa_processed_dates\n",
    "    project_table['Invoice Date'] = parsed_oa_invoiced_dates\n",
    "    project_table['R4F'] = parsed_approved_for_inspection_dates\n",
    "    \n",
    "    # deleting columns not needed in the production datestamp info\n",
    "    del project_table['Updated OA Processed'], project_table['Updated OA Invoiced'], project_table['Updated R4F'],project_table['Supplier Name'], project_table['Building Department'], project_table['Permit Req?'], project_table['On Hold?'], project_table['Branch']\n",
    "    \n",
    "    \n",
    "    return project_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datestamp_database():\n",
    "    \n",
    "    # assigning the functions to variables to be able to merge them\n",
    "    production_table = cleanup_project_workflow_dates()\n",
    "    sales_table = cleanup_workflow_dates()\n",
    "    reject_table = create_rejection_table()\n",
    "    change_order_table = create_change_order_table()\n",
    "    labor_adjustment_table = create_labor_adjustment_table()\n",
    "    \n",
    "    del reject_table['Scope Rejections']\n",
    "    del labor_adjustment_table['Labor Adjustments']\n",
    "    del change_order_table['Change Orders']\n",
    "\n",
    "    datestamped_workflow_table = sales_table.merge(\n",
    "        production_table, how='left', on='Job #').merge(\n",
    "        reject_table, how='left', on='Claim #').merge(\n",
    "        change_order_table, how='left', on='Job #').merge(\n",
    "        labor_adjustment_table, how='left', on='Job #')\n",
    "    \n",
    "    # renaming the combined data\n",
    "    datestamped_workflow_table = datestamped_workflow_table.rename(columns={\n",
    "    'Claim # Date': 'Rep Agreement Signed',\n",
    "    'FTA Scope. Req Date': 'Rep Claim Collected',\n",
    "    'Most Recent Rejection': 'FTA Scope Rejected',\n",
    "    'Submit for Estimate Date': 'FTA Scope Completed',\n",
    "    '[B] Created Estimate Date': 'BC Estimate Completed',\n",
    "    '[OB] Created Scope Calc': 'OB Scope Completed',\n",
    "    'Job Submittal Date': 'Sup Job Submitted',\n",
    "    '[B] - Date Approved by BC': 'BC Approved for Production',\n",
    "    '[OB] Completed': 'OB Order Built',\n",
    "    'Permit Applied [A]': 'PA Permit Applied',\n",
    "    'Order Date': 'GM Order Processed',\n",
    "    'Permit Received': 'PA Permit Processed',\n",
    "    'OA Date': 'PA OA Processed',\n",
    "    'Invoice Date': 'PA OA Invoiced',\n",
    "    'Ntfd H.O. Dlvry': 'PA Notify of Delivery',\n",
    "    'Dlvry Start': 'Delivery Date',\n",
    "    'Ntfd H.O. Start': 'PA Notify of Start',\n",
    "    'Roof Complete Date': 'Roof End',\n",
    "    'R4F': 'GM Approved for Inspection',\n",
    "    'Requested Final Insp': 'RA Inspection Requested',\n",
    "    'Final Inspection Date': 'RA Inspection Processed',\n",
    "    'COC Rcvd Date [A]': 'Rep COC Collected',\n",
    "    'Job Docs Scanned': 'SA Job Docs Uploaded',\n",
    "    '[B] Sent Invoice Packet to Ins Co': 'BC Project Invoiced',\n",
    "    '[B] Settled with Insurance': 'BC Project Closed'})\n",
    "    \n",
    "    \n",
    "    # Organizing combined Data to follow Workflow\n",
    "    all_project_df = datestamped_workflow_table[[\n",
    "        'Claim #',\n",
    "        'Job #',\n",
    "        'Branch',\n",
    "        'Claim Status',\n",
    "        'Rep Agreement Signed',\n",
    "        'Rep Claim Collected',\n",
    "        'FTA Scope Completed',\n",
    "        'FTA Scope Rejected',\n",
    "        'BC Estimate Completed',\n",
    "        'OB Scope Completed',\n",
    "        'Sup Job Submitted',\n",
    "        'BC Approved for Production',\n",
    "        'OB Order Built',\n",
    "        'GM Order Processed',\n",
    "        'PA Permit Applied',\n",
    "        'PA Permit Processed',\n",
    "        'PA OA Processed',\n",
    "        'PA OA Invoiced',\n",
    "        'PA Notify of Delivery',\n",
    "        'PA Notify of Start',\n",
    "        'Delivery Date',\n",
    "        'Roof Start',\n",
    "        'Roof End',\n",
    "        'GM Approved for Inspection',\n",
    "        'GM Change Order Date',\n",
    "        'GM Labor Adjustment Date',\n",
    "        'RA Inspection Requested',\n",
    "        'RA Inspection Processed',\n",
    "        'Rep COC Collected',\n",
    "        'SA Job Docs Uploaded',\n",
    "        'BC Project Invoiced',\n",
    "        'BC Project Closed']]\n",
    "    \n",
    "    return all_project_df\n",
    "\n",
    "# create_datestamp_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_info_database():\n",
    "    \n",
    "    # assigning the functions to variables to be able to merge them\n",
    "    info_table = create_project_info_table()\n",
    "    production_table = create_project_production_table()\n",
    "    reject_table = create_rejection_table()\n",
    "    change_order_table = create_change_order_table()\n",
    "    labor_adjustment_table = create_labor_adjustment_table()\n",
    "    \n",
    "    # creating smaller sets of data to merge to the 'info_table'\n",
    "    production_info = production_table[['Job #', 'Supplier Name', 'Building Department', 'Permit Req?']]\n",
    "    rejection_info = reject_table[['Claim #', 'Scope Rejections']]\n",
    "    change_order_info = change_order_table[['Job #', 'Change Orders']]\n",
    "    labor_adjustment_info = labor_adjustment_table[['Job #', 'Labor Adjustments']]\n",
    "    \n",
    "    \n",
    "    # merging the relevant data to the 'info_table'\n",
    "    info_table = info_table.merge(\n",
    "        production_info, how='left', on='Job #').merge(\n",
    "        rejection_info, how='left', on='Claim #').merge(\n",
    "        change_order_info, how='left', on='Job #').merge(\n",
    "        labor_adjustment_info, how='left', on='Job #')\n",
    "    \n",
    "    # Organizing Project Info Data\n",
    "    info_table = info_table[[\n",
    "        'Claim #',\n",
    "        'Job #',\n",
    "        'Branch',\n",
    "        'City',\n",
    "        'Building Department',\n",
    "        'Permit Req?',\n",
    "        'Supplier Name',\n",
    "        'Crew',\n",
    "        'Insurance Company',\n",
    "        'Scope Rejections',\n",
    "        'Change Orders',\n",
    "        'Labor Adjustments']]\n",
    "        \n",
    "    return info_table\n",
    "\n",
    "# create_info_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_workflow_database():\n",
    "    \n",
    "    # will store this project info\n",
    "    claim_num = []\n",
    "    job_num = []\n",
    "    branch_list = []\n",
    "    claim_status_list = []\n",
    "\n",
    "    # will store these date diffs\n",
    "    rep_claim_diff = []\n",
    "    fta_scope_diff = []\n",
    "    ob_scope_diff = []\n",
    "    bc_estimate_diff = []\n",
    "    sup_pfynr_diff = []\n",
    "    bc_approval_diff = []\n",
    "    ob_order_build_diff = []\n",
    "    gm_create_order_diff = []\n",
    "    pa_oa_processed_diff = []\n",
    "    pa_invoice_diff = []\n",
    "    gm_approval_diff = []\n",
    "    ra_request_inspection_diff = []\n",
    "    rep_coc_collected_diff = []\n",
    "    sa_docs_uploaded_diff = []\n",
    "    bc_project_invoiced_diff = []\n",
    "    bc_project_closed_diff = []\n",
    "\n",
    "    # this data applies to leadtimes, not workflow\n",
    "    pa_permit_applied_diff = []\n",
    "    pa_permit_processed_diff = []\n",
    "    pa_notify_delivery_diff = []\n",
    "    pa_notify_start_diff = []\n",
    "    \n",
    "    # saving the 'datestamp database' to a variable to iterate over\n",
    "    all_project_df = create_datestamp_database()\n",
    "    \n",
    "    # iterating over the df to create 'date diff' variables\n",
    "    for index, row in all_project_df.iterrows():\n",
    "\n",
    "        # creating 'date_diff' variables for each step in the workflow\n",
    "        rep_claim_date_diff = float((row['Rep Claim Collected'] - row['Rep Agreement Signed']).days)\n",
    "\n",
    "        # if the bc estimate was created prior to July 16th...\n",
    "        if row['BC Estimate Completed'] <= datetime(2019, 7, 15):\n",
    "\n",
    "            # and if the record did NOT had the FTA Scope Rejected...\n",
    "            if row['FTA Scope Rejected'] != row['FTA Scope Rejected']:\n",
    "\n",
    "                # then compare the date diffs using the 'fta scope completed' date field\n",
    "                fta_date_diff = (row['FTA Scope Completed'] - row['Rep Claim Collected']).days\n",
    "                ob_scope_date_diff = (row['OB Scope Completed'] - row['FTA Scope Completed']).days\n",
    "                bc_estimate_date_diff = (row['BC Estimate Completed'] - row['OB Scope Completed']).days\n",
    "                sup_pfynr_date_diff = (row['Sup Job Submitted'] - row['BC Estimate Completed']).days\n",
    "\n",
    "            # but if the record has had the FTA Scope Rejected...\n",
    "            else:\n",
    "                # then compare the 'FTA Scope rejected' date field\n",
    "                fta_date_diff = (row['FTA Scope Rejected'] - row['Rep Claim Collected']).days\n",
    "                ob_scope_date_diff = (row['OB Scope Completed'] - row['FTA Scope Rejected']).days\n",
    "                bc_estimate_date_diff = (row['BC Estimate Completed'] - row['OB Scope Completed']).days\n",
    "                sup_pfynr_date_diff = (row['Sup Job Submitted'] - row['OB Scope Completed']).days\n",
    "\n",
    "        # if the bc estimate was addressed during the 'blip' on 7/16-7/17...\n",
    "        elif row['BC Estimate Completed'] == datetime(2019, 7, 16) or row['BC Estimate Completed'] == datetime(2019, 7, 17):\n",
    "\n",
    "            # and if the record did NOT had the FTA Scope Rejected...\n",
    "            if row['FTA Scope Rejected'] != row['FTA Scope Rejected']:\n",
    "                # then compare the 'bc estimate' to the 'blip' date, and the 'ob scope' date to the new 'bc date'\n",
    "                fta_date_diff = (row['FTA Scope Completed'] - row['Rep Claim Collected']).days\n",
    "                bc_estimate_date_diff = (row['BC Estimate Completed'] - datetime(2019, 7, 16)).days\n",
    "                ob_scope_date_diff = (row['OB Scope Completed'] - row['BC Estimate Completed']).days\n",
    "                sup_pfynr_date_diff = (row['Sup Job Submitted'] - row['OB Scope Completed']).days\n",
    "\n",
    "            # but if the record has had the FTA Scope rejected...\n",
    "            else:\n",
    "                # then compare the 'fta scope rejected' date field\n",
    "                fta_date_diff = (row['FTA Scope Rejected'] - row['Rep Claim Collected']).days\n",
    "                bc_estimate_date_diff = (row['BC Estimate Completed'] - datetime(2019, 7, 16)).days\n",
    "                ob_scope_date_diff = (row['OB Scope Completed'] - row['FTA Scope Rejected']).days\n",
    "                sup_pfynr_date_diff = (row['Sup Job Submitted'] - row['OB Scope Completed']).days\n",
    "\n",
    "        # if the bc estimate was created after the 'blip'...\n",
    "        else:\n",
    "            # and if the record did NOT had the FTA Scope Rejected...\n",
    "            if row['FTA Scope Rejected'] != row['FTA Scope Rejected']:\n",
    "                # then compare the 'fta scope completed' date field\n",
    "                fta_date_diff = (row['FTA Scope Completed'] - row['Rep Claim Collected']).days\n",
    "                bc_estimate_date_diff = (row['BC Estimate Completed'] - row['FTA Scope Completed']).days\n",
    "                ob_scope_date_diff = (row['OB Scope Completed'] - row['BC Estimate Completed']).days\n",
    "                sup_pfynr_date_diff = (row['Sup Job Submitted'] - row['OB Scope Completed']).days\n",
    "\n",
    "            else:\n",
    "                # then compare the 'fta scope rejected' date field\n",
    "                fta_date_diff = (row['FTA Scope Rejected'] - row['Rep Claim Collected']).days\n",
    "                bc_estimate_date_diff = (row['BC Estimate Completed'] - row['FTA Scope Completed']).days\n",
    "                ob_scope_date_diff = (row['OB Scope Completed'] - row['FTA Scope Rejected']).days\n",
    "                sup_pfynr_date_diff = (row['Sup Job Submitted'] - row['OB Scope Completed']).days\n",
    "\n",
    "        # due to manual OA 'Processed' and 'Invoice' date fields, PAs have been recording false dates...\n",
    "        if row['PA OA Invoiced'] < row['PA OA Processed']:\n",
    "\n",
    "            # ...which provide no advantage to the project.\n",
    "            row['PA OA Invoiced'] = row['PA OA Processed'] + timedelta(days=1)\n",
    "\n",
    "        # OAs can't be invoiced before they have been processed (approved)\n",
    "        pa_invoice_date_diff = (row['PA OA Invoiced'] - row['PA OA Processed']).days\n",
    "\n",
    "        # due to manual 'Approved for inspection' (R4F) date field, GMs have been recording false dates...\n",
    "        if row['GM Approved for Inspection'] < row['Roof End']:\n",
    "\n",
    "            # ...which provide no advantage to the project; those will be reset to the day after the build.\n",
    "            row['GM Approved for Inspection'] = row['Roof End'] + timedelta(days=1)\n",
    "\n",
    "        # roofs can't be approved for inspection prior to the roof being built\n",
    "        gm_approval_date_diff = (row['GM Approved for Inspection'] - row['Roof End']).days\n",
    "\n",
    "        # due to manual 'COC Collected' (COC Rcvd [A]) date field, SAs have been recording false dates...\n",
    "        if row['Rep COC Collected'] < row['Roof End']:\n",
    "\n",
    "            # ...these will be reset for after the build.\n",
    "            row['Rep COC Collected'] = row['Roof End'] + timedelta(days=1)\n",
    "\n",
    "        # coc's can't be collected until after the roof is built, not before\n",
    "        rep_coc_collected_date_diff = (row['Rep COC Collected'] - row['Roof End']).days\n",
    "\n",
    "        # these dates do not have any special circumstances and can be directly compared\n",
    "        bc_approval_date_diff = (row['BC Approved for Production'] - row['Sup Job Submitted']).days\n",
    "        ob_orderbuild_date_diff = (row['OB Order Built'] - row['BC Approved for Production']).days\n",
    "        gm_create_order_date_diff = (row['GM Order Processed'] - row['OB Order Built']).days\n",
    "        ra_requested_inspection_date_diff = (row['RA Inspection Requested'] - row['GM Approved for Inspection']).days\n",
    "        sa_docs_uploaded_date_diff = (row['SA Job Docs Uploaded'] - row['Rep COC Collected']).days\n",
    "        bc_project_invoiced_date_diff = (row['BC Project Invoiced'] - row['SA Job Docs Uploaded']).days\n",
    "        bc_project_closed_date_diff = (row['BC Project Closed'] - row['BC Project Invoiced']).days\n",
    "\n",
    "        # these dates are manual, outliers are due to incorrect / false data entry\n",
    "        pa_oa_processed_date_diff = (row['PA OA Processed'] - row['GM Order Processed']).days\n",
    "\n",
    "        # these provide the lead times of tasks not directly impacting the workflow.\n",
    "        pa_permit_applied_date_diff = (row['PA Permit Applied'] - row['BC Approved for Production']).days\n",
    "        pa_permit_processed_date_diff = (row['PA Permit Processed'] - row['PA Permit Applied']).days\n",
    "        pa_notify_delivery_date_diff = (row['Delivery Date'] - row['PA Notify of Delivery']).days\n",
    "        pa_notify_start_date_diff = (row['Roof Start'] - row['PA Notify of Start']).days\n",
    "\n",
    "    ####################################################################################################\n",
    "        # appending 'date diff' values to lists to create each df column\n",
    "\n",
    "        claim_num.append(row[\"Claim #\"])\n",
    "        branch_list.append(row['Branch'])\n",
    "        claim_status_list.append(row['Claim Status'])\n",
    "        rep_claim_diff.append(rep_claim_date_diff)\n",
    "        fta_scope_diff.append(fta_date_diff)\n",
    "        ob_scope_diff.append(ob_scope_date_diff)\n",
    "        bc_estimate_diff.append(bc_estimate_date_diff)\n",
    "        sup_pfynr_diff.append(sup_pfynr_date_diff)\n",
    "        bc_approval_diff.append(bc_approval_date_diff)\n",
    "        ob_order_build_diff.append(ob_orderbuild_date_diff)\n",
    "        gm_create_order_diff.append(gm_create_order_date_diff)\n",
    "        pa_oa_processed_diff.append(pa_oa_processed_date_diff)\n",
    "        pa_invoice_diff.append(pa_invoice_date_diff)\n",
    "        gm_approval_diff.append(gm_approval_date_diff)\n",
    "        rep_coc_collected_diff.append(rep_coc_collected_date_diff)\n",
    "        sa_docs_uploaded_diff.append(sa_docs_uploaded_date_diff)\n",
    "        bc_project_invoiced_diff.append(bc_project_invoiced_date_diff)\n",
    "        bc_project_closed_diff.append(bc_project_closed_date_diff)\n",
    "\n",
    "        # this data applies to leadtimes, not workflow\n",
    "        pa_permit_applied_diff.append(pa_permit_applied_date_diff)\n",
    "        pa_permit_processed_diff.append(pa_permit_processed_date_diff)\n",
    "        pa_notify_delivery_diff.append(pa_notify_delivery_date_diff)\n",
    "        pa_notify_start_diff.append(pa_notify_start_date_diff)\n",
    "        ra_request_inspection_diff.append(ra_requested_inspection_date_diff)\n",
    "    ####################################################################################################\n",
    "\n",
    "    # Creating 'Workflow Days' df\n",
    "    days_df = pd.DataFrame({\n",
    "        \"Claim #\": claim_num,\n",
    "        \"Rep Collecting Claim\": rep_claim_diff,\n",
    "        \"FTA Completing Scope\": fta_scope_diff,\n",
    "        \"BC Completing Estimate\": bc_estimate_diff,\n",
    "        \"OB Completing Scope\": ob_scope_diff,\n",
    "        \"Sup Submitting Job\": sup_pfynr_diff,\n",
    "        \"BC Approving Job\": bc_approval_diff,\n",
    "        \"OB Building Order\": ob_order_build_diff,\n",
    "        \"GM Processing Order\": gm_create_order_diff,\n",
    "        \"PA Processing OA\": pa_oa_processed_diff,\n",
    "        \"PA Invoicing OA\": pa_invoice_diff,\n",
    "        'GM Approving for Inspection': gm_approval_diff,\n",
    "        'RA Requesting Inspection': ra_request_inspection_diff,\n",
    "        'Rep Collecting COC': rep_coc_collected_diff,\n",
    "        'SA Uploading Docs': sa_docs_uploaded_diff,\n",
    "        'BC Invoicing Project': bc_project_invoiced_diff,\n",
    "        'BC Closed Project': bc_project_closed_diff\n",
    "    })\n",
    "\n",
    "    # creating a column holding the running tally across a row (project)\n",
    "    # can be done because not including 'date diffs' on non-workflow items\n",
    "    days_df['Days in Pipeline'] = days_df.sum(axis=1)\n",
    "    \n",
    "    return days_df\n",
    "\n",
    "# create_workflow_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Database Tables Created'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_database_tables():\n",
    "    datestamp_table = create_datestamp_database()\n",
    "    workflow_table = create_workflow_database()\n",
    "    info_table = create_info_database()\n",
    "    \n",
    "    datestamp_table.to_csv(\"data/cleaned_data/project_table.csv\", index=False)\n",
    "    workflow_table.to_csv(\"data/cleaned_data/workflow_table.csv\", index=False)\n",
    "    info_table.to_csv(\"data/cleaned_data/project_info_table.csv\", index=False)\n",
    "    \n",
    "    return (f\"Database Tables Created\")\n",
    "\n",
    "create_database_tables()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": "50",
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
